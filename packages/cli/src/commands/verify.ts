/**
 * Verify Command
 * 
 * Verify code against ISL specifications and print evidence score.
 * 
 * Usage:
 *   isl verify --impl <file>                    # Auto-discover specs
 *   isl verify --spec <path> --impl <file>      # Specific spec
 *   isl verify --report <path>                  # Write evidence report
 *   isl verify --json                           # JSON output
 *   isl verify --smt                            # Enable SMT verification
 */

import { readFile, writeFile, mkdir } from 'fs/promises';
import { existsSync } from 'fs';
import { resolve, relative, dirname, basename, join } from 'path';
import { glob } from 'glob';
import chalk from 'chalk';
import ora from 'ora';
import { parse as parseISL, type Domain } from '@isl-lang/parser';
import { verify as verifyDomain, type VerificationResult, type TrustScore, type TestResult } from '@isl-lang/isl-verify';
import {
  buildModuleGraph,
  getMergedAST,
  formatErrors as formatResolverErrors,
} from '@isl-lang/import-resolver';
import { output } from '../output.js';
import { loadConfig } from '../config.js';
import { loadShipGateConfig } from '../config/loader.js';
import picomatch from 'picomatch';
import {
  filterVerifiableFiles,
  findMissingRequiredSpecs,
} from '../config/glob-matcher.js';
import { DEFAULT_SHIPGATE_CONFIG, DEFAULT_IGNORE } from '../config/schema.js';
import {
  generateUtilitySpec,
  classifyTier,
  calculateWeightedTrustScore,
} from '../auto-spec/index.js';
import { withSpan, ISL_ATTR } from '@isl-lang/observability';
import type { TemporalClauseResult } from '@isl-lang/verifier-temporal';
import { formatGitLab, formatJUnit } from './output-formats.js';
import { safeJSONStringify } from '@isl-lang/secrets-hygiene';

// Re-export types for use
export type { VerificationResult, TrustScore, TestResult };

// ─────────────────────────────────────────────────────────────────────────────
// Types
// ─────────────────────────────────────────────────────────────────────────────

export interface VerifyOptions {
  /** ISL spec file path (optional - auto-discovers if not provided) */
  spec?: string;
  /** Implementation file path */
  impl?: string;
  /** Report output path */
  report?: string;
  /** JSON output */
  json?: boolean;
  /** Verbose output */
  verbose?: boolean;
  /** Test timeout in milliseconds */
  timeout?: number;
  /** Minimum trust score to pass */
  minScore?: number;
  /** Show detailed breakdown */
  detailed?: boolean;
  /** Output format (legacy support) */
  format?: 'text' | 'json';
  /** Enable SMT verification for preconditions/postconditions */
  smt?: boolean;
  /** SMT solver timeout in milliseconds (default: 5000) */
  smtTimeout?: number;
  /** SMT solver to use: 'builtin', 'z3', 'cvc5', or 'auto' (default: 'auto') */
  smtSolver?: 'builtin' | 'z3' | 'cvc5' | 'auto';
  /** Enable property-based testing */
  pbt?: boolean;
  /** Number of PBT test iterations (default: 100) */
  pbtTests?: number;
  /** PBT random seed for reproducibility */
  pbtSeed?: number;
  /** Maximum PBT shrinking iterations (default: 100) */
  pbtMaxShrinks?: number;
  /** Enable temporal verification (latency SLAs, eventually within) */
  temporal?: boolean;
  /** Minimum samples for temporal verification (default: 10) */
  temporalMinSamples?: number;
  /** Trace files to use for temporal verification */
  temporalTraceFiles?: string[];
  /** Trace directory to search for trace files */
  temporalTraceDir?: string;
  /** Enable reality probe (route and env var verification) */
  reality?: boolean;
  /** Base URL for reality probe (e.g., http://localhost:3000) */
  realityBaseUrl?: string;
  /** Path to route map or OpenAPI spec (default: .shipgate/truthpack/routes.json) */
  realityRouteMap?: string;
  /** Path to env vars JSON (default: .shipgate/truthpack/env.json) */
  realityEnvVars?: string;
  /** Enable import resolution (resolves use statements and imports) */
  resolveImports?: boolean;
  /** Suppress spinner output (used when running in batch/unified mode) */
  quiet?: boolean;
  /** Guardrail policy overrides (from .shipgate.yml) */
  guardrails?: {
    allowAutoSpecShip?: boolean;
    allowNoTestExecution?: boolean;
    allowEmptyCategories?: boolean;
    allowUnvalidatedAiRules?: boolean;
  };
  /** Path to the config file that set guardrail overrides (for audit trail) */
  guardrailConfigSource?: string | null;
  /** Whether the spec was auto-generated */
  autoGeneratedSpec?: boolean;
}

export interface VerifyResult {
  success: boolean;
  specFile: string;
  implFile: string;
  verification?: VerificationResult;
  trustScore?: number;
  evidenceScore?: EvidenceScore;
  /** SMT verification results (when --smt flag is used) */
  smtResult?: SMTVerifyResult;
  /** PBT verification results (when --pbt flag is used) */
  pbtResult?: PBTVerifyResultType;
  /** Temporal verification results (when --temporal flag is used) */
  temporalResult?: TemporalVerifyResult;
  /** Reality probe results (when --reality flag is used) */
  realityResult?: import('@isl-lang/reality-probe').RealityProbeResult;
  errors: string[];
  duration: number;
}

/** Temporal verification result type */
export interface TemporalVerifyResult {
  /** Overall success */
  success: boolean;
  /** Results per temporal clause */
  clauses: TemporalClauseResult[];
  /** Summary statistics */
  summary: {
    total: number;
    proven: number;
    notProven: number;
    incomplete: number;
    unknown: number;
  };
  /** Total duration */
  duration: number;
}

/** PBT verification result type */
export interface PBTVerifyResultType {
  /** Overall success */
  success: boolean;
  /** Results per behavior */
  behaviors: Array<{
    behaviorName: string;
    success: boolean;
    testsRun: number;
    testsPassed: number;
    violations: Array<{
      property: string;
      type: string;
      error: string;
    }>;
    error?: string;
  }>;
  /** Summary statistics */
  summary: {
    totalBehaviors: number;
    passedBehaviors: number;
    failedBehaviors: number;
    totalTests: number;
    passedTests: number;
    failedTests: number;
  };
  /** Configuration used */
  config: {
    numTests: number;
    seed?: number;
    maxShrinks: number;
  };
  /** Total duration */
  duration: number;
}

/** SMT verification result */
export interface SMTVerifyResult {
  /** Overall success (no unsat/error in critical checks) */
  success: boolean;
  /** Individual check results */
  checks: SMTCheckItem[];
  /** Summary statistics */
  summary: {
    total: number;
    sat: number;
    unsat: number;
    unknown: number;
    timeout: number;
    error: number;
  };
  /** Total duration */
  duration: number;
}

/** Individual SMT check item */
export interface SMTCheckItem {
  kind: 'precondition_satisfiability' | 'postcondition_implication' | 'refinement_constraint';
  name: string;
  status: 'sat' | 'unsat' | 'unknown' | 'timeout' | 'error';
  message?: string;
  duration: number;
}

export interface EvidenceScore {
  /** Overall evidence score (0-100) */
  overall: number;
  /** Confidence level (0-100) */
  confidence: number;
  /** Categories breakdown */
  categories: {
    postconditions: CategoryEvidence;
    invariants: CategoryEvidence;
    scenarios: CategoryEvidence;
    temporal: CategoryEvidence;
  };
  /** Human-readable recommendation */
  recommendation: string;
  /** Number of passing checks */
  passedChecks: number;
  /** Number of failing checks */
  failedChecks: number;
  /** Total checks */
  totalChecks: number;
}

export interface CategoryEvidence {
  score: number;
  passed: number;
  failed: number;
  total: number;
  weight: number;
}

// ─────────────────────────────────────────────────────────────────────────────
// Spec Discovery
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Auto-discover ISL spec files
 * Searches in .shipgate/specs/*.isl, specs/*.isl, and *.isl in cwd
 */
async function discoverSpecs(cwd: string = process.cwd()): Promise<string[]> {
  const searchPaths = [
    '.shipgate/specs/**/*.isl',
    'specs/**/*.isl',
    '*.isl',
  ];

  const specs: string[] = [];

  for (const pattern of searchPaths) {
    const matches = await glob(pattern, {
      cwd,
      ignore: [...DEFAULT_IGNORE],
      absolute: true,
    });
    specs.push(...matches);
  }

  // Deduplicate
  return [...new Set(specs)];
}

/**
 * Resolve spec file path
 * If not provided, auto-discovers specs
 */
async function resolveSpec(specPath?: string): Promise<string[]> {
  if (specPath) {
    const resolved = resolve(specPath);
    
    // Check if it's a glob pattern
    if (specPath.includes('*')) {
      const matches = await glob(specPath, {
        cwd: process.cwd(),
        absolute: true,
      });
      return matches;
    }
    
    // Check if it's a directory
    if (existsSync(resolved)) {
      const stat = await import('fs').then(fs => fs.promises.stat(resolved));
      if (stat.isDirectory()) {
        const matches = await glob('**/*.isl', {
          cwd: resolved,
          absolute: true,
        });
        return matches;
      }
    }
    
    return [resolved];
  }

  // Auto-discover
  return discoverSpecs();
}

// ─────────────────────────────────────────────────────────────────────────────
// Evidence Score Calculation
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Calculate evidence score from trust score and additional verification results
 * Evidence score represents how much empirical evidence supports the implementation
 * 
 * BUG-001 FIX: Now incorporates PBT/SMT/temporal results into the score calculation
 */
function calculateEvidenceScore(
  trustScore: TrustScore,
  additionalResults?: {
    smtResult?: SMTVerifyResult;
    pbtResult?: PBTVerifyResultType;
    temporalResult?: TemporalVerifyResult;
    realityResult?: import('@isl-lang/reality-probe').RealityProbeResult;
  }
): EvidenceScore {
  const { breakdown } = trustScore;
  
  // Weight definitions (should match TrustCalculator)
  const weights = {
    postconditions: 40,
    invariants: 30,
    scenarios: 20,
    temporal: 10,
  };

  // Start with base breakdown from trust score
  let postconditionsPassed = breakdown.postconditions.passed;
  let postconditionsFailed = breakdown.postconditions.failed;
  let invariantsPassed = breakdown.invariants.passed;
  let invariantsFailed = breakdown.invariants.failed;
  let scenariosPassed = breakdown.scenarios.passed;
  let scenariosFailed = breakdown.scenarios.failed;
  let temporalPassed = breakdown.temporal.passed;
  let temporalFailed = breakdown.temporal.failed;

  // Incorporate PBT results into postconditions and invariants
  if (additionalResults?.pbtResult) {
    const pbt = additionalResults.pbtResult;
    for (const behavior of pbt.behaviors) {
      for (const violation of behavior.violations) {
        if (violation.type === 'postcondition') {
          postconditionsFailed++;
        } else if (violation.type === 'invariant') {
          invariantsFailed++;
        } else {
          scenariosFailed++;
        }
      }
      // Count passed tests
      if (behavior.success) {
        postconditionsPassed++;
      }
    }
  }

  // Incorporate SMT results into postconditions
  if (additionalResults?.smtResult) {
    const smt = additionalResults.smtResult;
    postconditionsPassed += smt.summary.sat;
    postconditionsFailed += smt.summary.unsat + smt.summary.error;
  }

  // Incorporate temporal results
  if (additionalResults?.temporalResult) {
    const temporal = additionalResults.temporalResult;
    temporalPassed += temporal.summary.proven;
    temporalFailed += temporal.summary.notProven;
  }

  // Incorporate reality probe results
  if (additionalResults?.realityResult) {
    const reality = additionalResults.realityResult;
    // Ghost routes and env vars are failures
    const realityFailed = reality.summary.ghostRoutes + reality.summary.ghostEnvVars;
    const realityPassed = (reality.summary.existingRoutes + reality.summary.existingEnvVars) - realityFailed;
    // Add to scenarios category (reality checks are scenario-like)
    scenariosPassed += realityPassed;
    scenariosFailed += realityFailed;
  }

  // Calculate totals for each category
  const postconditionsTotal = postconditionsPassed + postconditionsFailed;
  const invariantsTotal = invariantsPassed + invariantsFailed;
  const scenariosTotal = scenariosPassed + scenariosFailed;
  const temporalTotal = temporalPassed + temporalFailed;

  // Calculate category scores (handle zero division)
  const calcScore = (passed: number, total: number) => 
    total > 0 ? Math.round((passed / total) * 100) : 100;

  const categories = {
    postconditions: {
      score: calcScore(postconditionsPassed, postconditionsTotal),
      passed: postconditionsPassed,
      failed: postconditionsFailed,
      total: postconditionsTotal,
      weight: weights.postconditions,
    },
    invariants: {
      score: calcScore(invariantsPassed, invariantsTotal),
      passed: invariantsPassed,
      failed: invariantsFailed,
      total: invariantsTotal,
      weight: weights.invariants,
    },
    scenarios: {
      score: calcScore(scenariosPassed, scenariosTotal),
      passed: scenariosPassed,
      failed: scenariosFailed,
      total: scenariosTotal,
      weight: weights.scenarios,
    },
    temporal: {
      score: calcScore(temporalPassed, temporalTotal),
      passed: temporalPassed,
      failed: temporalFailed,
      total: temporalTotal,
      weight: weights.temporal,
    },
  };

  // Count totals
  const passedChecks = postconditionsPassed + invariantsPassed + scenariosPassed + temporalPassed;
  const failedChecks = postconditionsFailed + invariantsFailed + scenariosFailed + temporalFailed;
  const totalChecks = passedChecks + failedChecks;

  // Calculate weighted overall score
  const totalWeight = weights.postconditions + weights.invariants + weights.scenarios + weights.temporal;
  const overallScore = Math.round(
    (categories.postconditions.score * weights.postconditions +
     categories.invariants.score * weights.invariants +
     categories.scenarios.score * weights.scenarios +
     categories.temporal.score * weights.temporal) / totalWeight
  );

  // Calculate confidence based on evidence count
  const confidence = totalChecks > 0 ? Math.min(Math.round((totalChecks / 10) * 100), 100) : 0;

  // Map recommendation to human-readable string based on recalculated score
  const recommendationMap: Record<string, string> = {
    production_ready: 'Production Ready - High confidence in implementation',
    staging_recommended: 'Staging Recommended - Good coverage, minor gaps',
    shadow_mode: 'Shadow Mode - Monitor in production shadow',
    not_ready: 'Not Ready - Significant evidence gaps',
    critical_issues: 'Critical Issues - Failing critical checks',
  };

  // Determine recommendation based on recalculated score
  let recommendation: string;
  if (failedChecks > 0 && overallScore < 70) {
    recommendation = recommendationMap.critical_issues;
  } else if (overallScore >= 95) {
    recommendation = recommendationMap.production_ready;
  } else if (overallScore >= 85) {
    recommendation = recommendationMap.staging_recommended;
  } else if (overallScore >= 70) {
    recommendation = recommendationMap.shadow_mode;
  } else {
    recommendation = recommendationMap.not_ready;
  }

  return {
    overall: overallScore,
    confidence,
    categories,
    recommendation,
    passedChecks,
    failedChecks,
    totalChecks,
  };
}

// ─────────────────────────────────────────────────────────────────────────────
// Evidence Report Generation
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Generate evidence report content
 * BUG-003 FIX: Now includes SMT/PBT/temporal results in the evidence bundle
 */
function generateEvidenceReport(result: VerifyResult): string {
  const timestamp = new Date().toISOString();
  const evidence = result.evidenceScore!;
  const verification = result.verification!;

  // Collect all failures from various sources
  const allFailures: Array<{ category: string; name: string; impact: string; error: string }> = [];
  
  // Add failures from trust score details
  for (const d of verification.trustScore.details.filter(d => d.status === 'failed')) {
    allFailures.push({
      category: d.category,
      name: d.name,
      impact: d.impact,
      error: d.message ?? 'Unknown error',
    });
  }

  // Add PBT failures
  if (result.pbtResult) {
    for (const behavior of result.pbtResult.behaviors) {
      for (const violation of behavior.violations) {
        allFailures.push({
          category: violation.type === 'postcondition' ? 'postconditions' : 
                   violation.type === 'invariant' ? 'invariants' : 'scenarios',
          name: `PBT: ${behavior.behaviorName} - ${violation.property}`,
          impact: 'high',
          error: violation.error,
        });
      }
    }
  }

  // Add SMT failures
  if (result.smtResult) {
    for (const check of result.smtResult.checks) {
      if (check.status === 'unsat' || check.status === 'error') {
        allFailures.push({
          category: 'postconditions',
          name: `SMT: ${check.name}`,
          impact: 'critical',
          error: check.message ?? `SMT check ${check.status}`,
        });
      }
    }
  }

  // Add temporal failures
  if (result.temporalResult) {
    for (const clause of result.temporalResult.clauses) {
      if (!clause.success) {
        allFailures.push({
          category: 'temporal',
          name: `Temporal: ${clause.clauseText}`,
          impact: 'medium',
          error: clause.error ?? `Temporal clause not proven: ${clause.verdict}`,
        });
      }
    }
  }

  return safeJSONStringify({
    metadata: {
      timestamp,
      specFile: result.specFile,
      implFile: result.implFile,
      duration: result.duration,
      version: '1.0.0',
    },
    evidenceScore: {
      overall: evidence.overall,
      confidence: evidence.confidence,
      recommendation: evidence.recommendation,
      summary: {
        passed: evidence.passedChecks,
        failed: evidence.failedChecks,
        total: evidence.totalChecks,
        passRate: evidence.totalChecks > 0 
          ? Math.round((evidence.passedChecks / evidence.totalChecks) * 100) 
          : 0,
      },
    },
    breakdown: {
      postconditions: {
        score: evidence.categories.postconditions.score,
        weight: evidence.categories.postconditions.weight,
        passed: evidence.categories.postconditions.passed,
        failed: evidence.categories.postconditions.failed,
        total: evidence.categories.postconditions.total,
      },
      invariants: {
        score: evidence.categories.invariants.score,
        weight: evidence.categories.invariants.weight,
        passed: evidence.categories.invariants.passed,
        failed: evidence.categories.invariants.failed,
        total: evidence.categories.invariants.total,
      },
      scenarios: {
        score: evidence.categories.scenarios.score,
        weight: evidence.categories.scenarios.weight,
        passed: evidence.categories.scenarios.passed,
        failed: evidence.categories.scenarios.failed,
        total: evidence.categories.scenarios.total,
      },
      temporal: {
        score: evidence.categories.temporal.score,
        weight: evidence.categories.temporal.weight,
        passed: evidence.categories.temporal.passed,
        failed: evidence.categories.temporal.failed,
        total: evidence.categories.temporal.total,
      },
    },
    testResults: {
      passed: verification.testResult.passed,
      failed: verification.testResult.failed,
      skipped: verification.testResult.skipped,
      duration: verification.testResult.duration,
      details: verification.trustScore.details.map(d => ({
        category: d.category,
        name: d.name,
        status: d.status,
        impact: d.impact,
        message: d.message ?? null,
      })),
    },
    // BUG-003 FIX: Include SMT results in evidence bundle
    smtResults: result.smtResult ? {
      success: result.smtResult.success,
      summary: result.smtResult.summary,
      checks: result.smtResult.checks.map(c => ({
        kind: c.kind,
        name: c.name,
        status: c.status,
        message: c.message ?? null,
        duration: c.duration,
      })),
      duration: result.smtResult.duration,
    } : null,
    // BUG-003 FIX: Include PBT results in evidence bundle
    pbtResults: result.pbtResult ? {
      success: result.pbtResult.success,
      summary: result.pbtResult.summary,
      behaviors: result.pbtResult.behaviors.map(b => ({
        behaviorName: b.behaviorName,
        success: b.success,
        testsRun: b.testsRun,
        testsPassed: b.testsPassed,
        violations: b.violations,
        error: b.error ?? null,
      })),
      config: result.pbtResult.config,
      duration: result.pbtResult.duration,
    } : null,
    // BUG-003 FIX: Include temporal results in evidence bundle
    temporalResults: result.temporalResult ? {
      success: result.temporalResult.success,
      summary: result.temporalResult.summary,
      clauses: result.temporalResult.clauses.map(c => ({
        clauseId: c.clauseId,
        type: c.type,
        clauseText: c.clauseText,
        verdict: c.verdict,
        success: c.success,
        timing: c.timing,
        error: c.error ?? null,
      })),
      duration: result.temporalResult.duration,
    } : null,
    // BUG-003 FIX: Consolidated failures from all sources
    failures: allFailures,
  }, null, 2);
}

/**
 * Write evidence report to file
 */
async function writeEvidenceReport(result: VerifyResult, reportPath: string): Promise<void> {
  const resolvedPath = resolve(reportPath);
  const dir = dirname(resolvedPath);
  
  // Ensure directory exists
  if (!existsSync(dir)) {
    await mkdir(dir, { recursive: true });
  }

  const content = generateEvidenceReport(result);
  await writeFile(resolvedPath, content, 'utf-8');
}

// ─────────────────────────────────────────────────────────────────────────────
// PBT Verification
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Run PBT verification on a domain AST
 * Generates random inputs satisfying preconditions and verifies postconditions
 */
async function runPBTVerification(
  domain: Domain,
  implSource: string,
  options: {
    numTests?: number;
    seed?: number;
    maxShrinks?: number;
    timeout?: number;
    verbose?: boolean;
  }
): Promise<PBTVerifyResultType> {
  const start = Date.now();
  const behaviors: PBTVerifyResultType['behaviors'] = [];

  try {
    // Dynamically import the PBT package
    const pbt = await import('@isl-lang/pbt');

    // Create a simple implementation wrapper from the source
    // In a full implementation, this would use dynamic evaluation
    // For now, we create a mock implementation that validates structure
    const createMockImpl = (behaviorName: string): any => ({ // pbt.BehaviorImplementation
      async execute(input: Record<string, unknown>): Promise<any> { // pbt.ExecutionResult
        // Basic validation based on behavior name
        // Real implementation would evaluate the actual implementation code
        const email = input.email as string | undefined;
        const password = input.password as string | undefined;

        // Validate input structure
        if (behaviorName.toLowerCase().includes('login')) {
          if (!email || !email.includes('@')) {
            return {
              success: false,
              error: { code: 'INVALID_INPUT', message: 'Invalid email format' },
            };
          }
          if (!password || password.length < 8 || password.length > 128) {
            return {
              success: false,
              error: { code: 'INVALID_INPUT', message: 'Invalid password length' },
            };
          }
        }

        // Default: assume success for valid inputs
        return { success: true };
      },
    });

    // Run PBT for each behavior
    for (const behavior of domain.behaviors) {
      const behaviorName = behavior.name.name;
      
      try {
        const impl = createMockImpl(behaviorName);
        const report = await pbt.runPBT(domain as any, behaviorName, impl, {
          numTests: options.numTests ?? 100,
          seed: options.seed,
          maxShrinks: options.maxShrinks ?? 100,
          timeout: options.timeout ?? 5000,
          verbose: options.verbose ?? false,
        });

        behaviors.push({
          behaviorName,
          success: report.success,
          testsRun: report.testsRun,
          testsPassed: report.testsPassed,
          violations: report.violations.map(v => ({
            property: v.property.name,
            type: v.property.type,
            error: v.error,
          })),
        });
      } catch (error) {
        behaviors.push({
          behaviorName,
          success: false,
          testsRun: 0,
          testsPassed: 0,
          violations: [],
          error: error instanceof Error ? error.message : String(error),
        });
      }
    }

    const passedBehaviors = behaviors.filter(b => b.success).length;
    const totalTests = behaviors.reduce((sum, b) => sum + b.testsRun, 0);
    const passedTests = behaviors.reduce((sum, b) => sum + b.testsPassed, 0);

    return {
      success: behaviors.every(b => b.success),
      behaviors,
      summary: {
        totalBehaviors: behaviors.length,
        passedBehaviors,
        failedBehaviors: behaviors.length - passedBehaviors,
        totalTests,
        passedTests,
        failedTests: totalTests - passedTests,
      },
      config: {
        numTests: options.numTests ?? 100,
        seed: options.seed,
        maxShrinks: options.maxShrinks ?? 100,
      },
      duration: Date.now() - start,
    };
  } catch (error) {
    // PBT package not available
    const message = error instanceof Error ? error.message : String(error);

    if (message.includes('Cannot find module') || message.includes('not found')) {
      return {
        success: true, // Don't fail if PBT package is not installed
        behaviors: [{
          behaviorName: 'pbt_module',
          success: true,
          testsRun: 0,
          testsPassed: 0,
          violations: [],
          error: 'PBT package not installed. Install with: pnpm add @isl-lang/pbt',
        }],
        summary: {
          totalBehaviors: 0,
          passedBehaviors: 0,
          failedBehaviors: 0,
          totalTests: 0,
          passedTests: 0,
          failedTests: 0,
        },
        config: { numTests: 0, maxShrinks: 0 },
        duration: Date.now() - start,
      };
    }

    return {
      success: false,
      behaviors: [{
        behaviorName: 'pbt_error',
        success: false,
        testsRun: 0,
        testsPassed: 0,
        violations: [],
        error: message,
      }],
      summary: {
        totalBehaviors: 1,
        passedBehaviors: 0,
        failedBehaviors: 1,
        totalTests: 0,
        passedTests: 0,
        failedTests: 0,
      },
      config: { numTests: 0, maxShrinks: 0 },
      duration: Date.now() - start,
    };
  }
}

// ─────────────────────────────────────────────────────────────────────────────
// Temporal Verification
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Run temporal verification on a domain AST
 * Verifies:
 * - within (latency SLAs with percentiles, e.g., "within 200ms (p50)")
 * - eventually within (event occurs within time bound, e.g., "eventually within 5s: audit log updated")
 */
async function runTemporalVerification(
  domain: Domain,
  options: { minSamples?: number; verbose?: boolean; traceFiles?: string[]; traceDir?: string }
): Promise<TemporalVerifyResult> {
  const start = Date.now();
  const clauses: TemporalClauseResult[] = [];

  try {
    // Dynamically import the temporal verifier
    const temporal = await import('@isl-lang/verifier-temporal');

    // Try to load traces if trace files/directory provided
    let traces: any[] = []; // Trace[] from trace-format
    let useTraceEvaluation = false;
    
    if (options.traceFiles && options.traceFiles.length > 0) {
      try {
        traces = await temporal.loadTraceFiles(options.traceFiles);
        useTraceEvaluation = true;
      } catch (error) {
        if (options.verbose) {
          console.warn(`Failed to load trace files: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
    } else if (options.traceDir) {
      try {
        const traceFiles = await temporal.discoverTraceFiles(options.traceDir);
        if (traceFiles.length > 0) {
          traces = await temporal.loadTraceFiles(traceFiles);
          useTraceEvaluation = true;
        }
      } catch (error) {
        if (options.verbose) {
          console.warn(`Failed to discover traces: ${error instanceof Error ? error.message : String(error)}`);
        }
      }
    }

    // Use trace-based evaluation if traces are available
    if (useTraceEvaluation && traces.length > 0) {
      const report = await temporal.evaluateTemporalProperties(
        domain as unknown as import('@isl-lang/isl-core').DomainDeclaration,
        traces,
        {
          minSnapshots: options.minSamples ?? 1,
        }
      );

      // Map evaluation results to clause format
      for (const evaluation of report.evaluations) {
        const behaviorName = (evaluation.requirement as any).behaviorName || 'unknown';
        const clauseId = `${behaviorName}:${evaluation.requirement.type}`;
        
        let type: 'within' | 'eventually_within' | 'always' | 'never' = 'within';
        if (evaluation.requirement.type === 'eventually') {
          type = 'eventually_within';
        } else if (evaluation.requirement.type === 'always') {
          type = 'always';
        } else if (evaluation.requirement.type === 'never') {
          type = 'never';
        }

        clauses.push({
          clauseId,
          type,
          clauseText: evaluation.description,
          verdict: evaluation.verdict === 'SATISFIED' ? 'PROVEN' :
                   evaluation.verdict === 'VIOLATED' ? 'NOT_PROVEN' :
                   evaluation.verdict === 'VACUOUSLY_TRUE' ? 'PROVEN' : 'UNKNOWN',
          success: evaluation.satisfied,
          timing: evaluation.requirement.duration ? {
            thresholdMs: durationToMs(evaluation.requirement.duration),
            percentile: evaluation.requirement.percentile ? parsePercentile(evaluation.requirement.percentile) : undefined,
            actualMs: evaluation.result.witnessTimeMs,
            sampleCount: evaluation.result.snapshotsEvaluated,
          } : undefined,
          error: evaluation.violation ? evaluation.violation.message : evaluation.result.explanation,
        });
      }

      const proven = clauses.filter(c => c.verdict === 'PROVEN').length;
      const notProven = clauses.filter(c => c.verdict === 'NOT_PROVEN').length;
      const incomplete = clauses.filter(c => c.verdict === 'INCOMPLETE_PROOF').length;
      const unknown = clauses.filter(c => c.verdict === 'UNKNOWN').length;

      return {
        success: report.success,
        clauses,
        summary: {
          total: clauses.length,
          proven,
          notProven,
          incomplete,
          unknown,
        },
        duration: Date.now() - start,
      };
    }

    // Fallback to original implementation-based verification
    // Extract temporal clauses from behaviors
    for (const behavior of domain.behaviors) {
      const behaviorName = behavior.name.name;
      const temporalBlock = behavior.temporal;
      
      if (!temporalBlock || !(temporalBlock as any).requirements || (temporalBlock as any).requirements.length === 0) {
        continue;
      }

      for (const req of (temporalBlock as any).requirements) {
        // Parse the temporal requirement
        const clauseId = `${behaviorName}:${req.type}`;
        const clauseText = formatTemporalRequirement(req);
        
        // Map ISL temporal types to verifier types
        let type: 'within' | 'eventually_within' | 'always' | 'never' = 'within';
        let thresholdMs: number | undefined;
        let percentile: number | undefined;
        let eventKind: string | undefined;

        if (req.type === 'within') {
          type = 'within';
          thresholdMs = req.duration ? durationToMs(req.duration) : undefined;
          percentile = req.percentile ? parsePercentile(req.percentile) : 99;
        } else if (req.type === 'eventually') {
          type = 'eventually_within';
          thresholdMs = req.duration ? durationToMs(req.duration) : 5000;
          // Extract event kind from the expression (simplified parsing)
          eventKind = extractEventKind(req);
        } else if (req.type === 'always') {
          type = 'always';
        } else if (req.type === 'never') {
          type = 'never';
        }

        // Run actual temporal verification using the verifier
        try {
          // Use the verifier's verify function for each behavior
          const verifyResult = await temporal.verify(
            '', // implementation path - not used for spec-only verification
            domain as unknown as Parameters<typeof temporal.verify>[1],
            behaviorName,
            { timeout: 5000, sampleCount: options.minSamples ?? 10 }
          );

          // Map verifier results to our clause format
          if (verifyResult.temporalResults && verifyResult.temporalResults.length > 0) {
            for (const tempResult of verifyResult.temporalResults) {
              clauses.push({
                clauseId: `${behaviorName}:${tempResult.type}`,
                type: tempResult.type as 'within' | 'eventually_within' | 'always' | 'never',
                clauseText: tempResult.description || clauseText,
                verdict: tempResult.success ? 'PROVEN' : 'NOT_PROVEN',
                success: tempResult.success,
                timing: {
                  thresholdMs: thresholdMs ?? 0,
                  percentile,
                  actualMs: tempResult.duration,
                  sampleCount: options.minSamples ?? 10,
                },
              });
            }
          } else {
            // No temporal results from verifier - create synthetic check
            clauses.push({
              clauseId,
              type,
              clauseText,
              verdict: verifyResult.verdict === 'verified' ? 'PROVEN' : 
                       verifyResult.verdict === 'unsafe' ? 'NOT_PROVEN' : 'INCOMPLETE_PROOF',
              success: verifyResult.success,
              timing: {
                thresholdMs: thresholdMs ?? 0,
                percentile,
                sampleCount: options.minSamples ?? 10,
              },
            });
          }
        } catch (verifyError) {
          // Fallback to synthetic result if verification fails
          clauses.push({
            clauseId,
            type,
            clauseText,
            verdict: 'INCOMPLETE_PROOF',
            success: false,
            timing: {
              thresholdMs: thresholdMs ?? 0,
              percentile,
              sampleCount: 0,
            },
            error: verifyError instanceof Error ? verifyError.message : 'Temporal verification failed',
          });
        }
      }
    }

    // Calculate summary
    const proven = clauses.filter(c => c.verdict === 'PROVEN').length;
    const notProven = clauses.filter(c => c.verdict === 'NOT_PROVEN').length;
    const incomplete = clauses.filter(c => c.verdict === 'INCOMPLETE_PROOF').length;
    const unknown = clauses.filter(c => c.verdict === 'UNKNOWN').length;

    return {
      success: clauses.length === 0 || (notProven === 0 && unknown === 0),
      clauses,
      summary: {
        total: clauses.length,
        proven,
        notProven,
        incomplete,
        unknown,
      },
      duration: Date.now() - start,
    };
  } catch (error) {
    // Temporal package not available
    const message = error instanceof Error ? error.message : String(error);

    if (message.includes('Cannot find module') || message.includes('not found')) {
      return {
        success: true, // Don't fail if temporal package is not installed
        clauses: [{
          clauseId: 'temporal_module',
          type: 'within',
          clauseText: 'temporal verification',
          verdict: 'UNKNOWN',
          success: false,
          error: 'Temporal package not installed. Install with: pnpm add @isl-lang/verifier-temporal',
        }],
        summary: { total: 0, proven: 0, notProven: 0, incomplete: 0, unknown: 1 },
        duration: Date.now() - start,
      };
    }

    return {
      success: false,
      clauses: [{
        clauseId: 'temporal_error',
        type: 'within',
        clauseText: 'temporal verification',
        verdict: 'UNKNOWN',
        success: false,
        error: message,
      }],
      summary: { total: 1, proven: 0, notProven: 0, incomplete: 0, unknown: 1 },
      duration: Date.now() - start,
    };
  }
}

/**
 * Format a temporal requirement as a human-readable string
 */
function formatTemporalRequirement(req: { type: string; duration?: { value: number; unit: string }; percentile?: string }): string {
  const parts: string[] = [req.type];
  
  if (req.duration) {
    parts.push(`${req.duration.value}${req.duration.unit}`);
  }
  
  if (req.percentile) {
    parts.push(`(${req.percentile})`);
  }
  
  return parts.join(' ');
}

/**
 * Convert duration to milliseconds
 */
function durationToMs(duration: { value: number; unit: string }): number {
  const value = duration.value;
  switch (duration.unit) {
    case 'ms': return value;
    case 's': return value * 1000;
    case 'm': return value * 60 * 1000;
    case 'h': return value * 60 * 60 * 1000;
    case 'd': return value * 24 * 60 * 60 * 1000;
    default: return value;
  }
}

/**
 * Parse percentile string (e.g., "p99" or "99") to number
 */
function parsePercentile(percentile: string): number {
  const cleaned = percentile.replace(/^p/i, '');
  return parseFloat(cleaned);
}

/**
 * Extract event kind from a temporal requirement expression
 */
function extractEventKind(req: { expression?: unknown }): string | undefined {
  // Simplified extraction - in a real implementation, this would
  // parse the expression AST to find the event kind
  return undefined;
}

// ─────────────────────────────────────────────────────────────────────────────
// SMT Verification
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Run SMT verification on a domain AST
 * Checks:
 * - Precondition satisfiability (are preconditions achievable?)
 * - Postcondition implications (do postconditions follow from preconditions?)
 * - Refinement type constraints (are constraints satisfiable?)
 */
async function runSMTVerification(
  domain: Domain,
  options: { timeout?: number; verbose?: boolean; solver?: 'builtin' | 'z3' | 'cvc5' | 'auto' }
): Promise<SMTVerifyResult> {
  const start = Date.now();
  const checks: SMTCheckItem[] = [];
  
  try {
    // Dynamically import the SMT package to keep it optional
    const { verifySMT, getBestAvailableSolver } = await import('@isl-lang/isl-smt');
    
    // Determine which solver to use
    let solver: 'builtin' | 'z3' | 'cvc5' = 'builtin';
    if (options.solver === 'auto' || !options.solver) {
      // Auto-detect best available solver
      const bestSolver = await getBestAvailableSolver();
      solver = bestSolver || 'builtin';
    } else {
      solver = options.solver;
    }
    
    const result = await verifySMT(domain, {
      timeout: options.timeout ?? 5000,
      verbose: options.verbose,
      solver,
    });
    
    // Convert to our format
    for (const r of result.results) {
      checks.push({
        kind: r.kind,
        name: r.name,
        status: r.result.status,
        message: r.result.status === 'error' ? r.result.message :
                 r.result.status === 'unknown' ? r.result.reason : undefined,
        duration: r.duration,
      });
    }
    
    return {
      success: result.summary.error === 0 && result.summary.unsat === 0,
      checks,
      summary: result.summary,
      duration: Date.now() - start,
    };
  } catch (error) {
    // SMT package not available or error occurred
    const message = error instanceof Error ? error.message : String(error);
    
    // Check if it's a module not found error
    if (message.includes('Cannot find module') || message.includes('not found')) {
      return {
        success: true, // Don't fail if SMT package is not installed
        checks: [{
          kind: 'precondition_satisfiability',
          name: 'smt_module',
          status: 'unknown',
          message: 'SMT package not installed. Install with: pnpm add @isl-lang/isl-smt',
          duration: 0,
        }],
        summary: { total: 0, sat: 0, unsat: 0, unknown: 1, timeout: 0, error: 0 },
        duration: Date.now() - start,
      };
    }
    
    return {
      success: false,
      checks: [{
        kind: 'precondition_satisfiability',
        name: 'smt_error',
        status: 'error',
        message,
        duration: 0,
      }],
      summary: { total: 1, sat: 0, unsat: 0, unknown: 0, timeout: 0, error: 1 },
      duration: Date.now() - start,
    };
  }
}

// ─────────────────────────────────────────────────────────────────────────────
// Verification Implementation
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Verify an implementation against a spec file
 */
export async function verify(specFile: string, options: VerifyOptions): Promise<VerifyResult> {
  const startTime = Date.now();
  const spinner = options.quiet
    ? ora({ isSilent: true, text: 'Loading files...' }).start()
    : ora('Loading files...').start();
  const errors: string[] = [];

  // Load config for defaults
  const { config } = await loadConfig();
  const timeout = options.timeout ?? config?.verify?.timeout ?? 30000;
  const minScore = options.minScore ?? config?.verify?.minTrustScore ?? 70;

  // Resolve paths
  const specPath = resolve(specFile);
  const implPath = options.impl ? resolve(options.impl) : '';

  // Validate impl path is provided
  if (!options.impl) {
    spinner.fail('Implementation file required');
    return {
      success: false,
      specFile: specPath,
      implFile: implPath,
      errors: ['Implementation file path is required (--impl <file>)'],
      duration: Date.now() - startTime,
    };
  }

  try {
    // Read spec file
    spinner.text = 'Parsing ISL spec...';
    const specSource = await readFile(specPath, 'utf-8');
    
    // Resolve imports if enabled (default: true)
    const resolveImports = options.resolveImports ?? true;
    let ast: Domain | undefined;
    
    if (resolveImports) {
      spinner.text = 'Resolving imports...';
      const graph = await buildModuleGraph(specPath, {
        basePath: dirname(specPath),
        enableImports: true,
        enableCaching: true,
        mergeAST: true,
      });
      
      if (graph.errors.length > 0) {
        // Check if errors are critical (circular deps, module not found)
        const criticalErrors = graph.errors.filter(e => 
          e.code === 'CIRCULAR_DEPENDENCY' || e.code === 'MODULE_NOT_FOUND'
        );
        
        if (criticalErrors.length > 0) {
          spinner.fail('Failed to resolve imports');
          return {
            success: false,
            specFile: specPath,
            implFile: implPath,
            errors: graph.errors.map(e => `Import error: ${e.message}`),
            duration: Date.now() - startTime,
          };
        }
        
        // Non-critical errors - warn but continue
        if (options.verbose) {
          for (const err of graph.errors) {
            output.debug(`[Import Warning] ${err.message}`);
          }
        }
      }
      
      // Use merged AST if available
      ast = getMergedAST(graph) as Domain | undefined;
      
      if (!ast && graph.graphModules.size > 0) {
        // Fallback to entry module's AST
        const entryModule = graph.graphModules.get(graph.entryPoint);
        ast = entryModule?.ast as Domain | undefined;
      }
    }
    
    // Fallback to single-file parsing if import resolution didn't work
    if (!ast) {
      const { domain: parsedAst, errors: parseErrors } = parseISL(specSource, specPath);
      
      if (parseErrors.length > 0 || !parsedAst) {
        spinner.fail('Failed to parse ISL spec');
        return {
          success: false,
          specFile: specPath,
          implFile: implPath,
          errors: parseErrors.map(e => `Parse error: ${e.message}`),
          duration: Date.now() - startTime,
        };
      }
      
      ast = parsedAst;
    }

    // Read implementation
    spinner.text = 'Loading implementation...';
    const implSource = await readFile(implPath, 'utf-8');

    // Run SMT verification if enabled
    let smtResult: SMTVerifyResult | undefined;
    if (options.smt) {
      spinner.text = 'Running SMT verification...';
      smtResult = await runSMTVerification(ast, {
        timeout: options.smtTimeout ?? 5000,
        verbose: options.verbose,
        solver: options.smtSolver ?? 'auto',
      });
      
      if (options.verbose) {
        spinner.info(`SMT verification: ${smtResult.summary.sat} sat, ${smtResult.summary.unsat} unsat, ${smtResult.summary.unknown} unknown`);
      }
    }

    // Run PBT verification if enabled
    let pbtResult: PBTVerifyResultType | undefined;
    if (options.pbt) {
      spinner.text = 'Running property-based tests...';
      pbtResult = await runPBTVerification(ast, implSource, {
        numTests: options.pbtTests ?? 100,
        seed: options.pbtSeed,
        maxShrinks: options.pbtMaxShrinks ?? 100,
        timeout: timeout,
        verbose: options.verbose,
      });
      
      if (options.verbose) {
        spinner.info(`PBT: ${pbtResult.summary.passedTests}/${pbtResult.summary.totalTests} tests passed across ${pbtResult.summary.totalBehaviors} behaviors`);
      }
    }

    // Run temporal verification if enabled
    let temporalResult: TemporalVerifyResult | undefined;
    if (options.temporal) {
      spinner.text = 'Running temporal verification...';
      temporalResult = await runTemporalVerification(ast, {
        minSamples: options.temporalMinSamples ?? 10,
        verbose: options.verbose,
        traceFiles: options.temporalTraceFiles,
        traceDir: options.temporalTraceDir,
      });
      
      if (options.verbose) {
        spinner.info(`Temporal: ${temporalResult.summary.proven}/${temporalResult.summary.total} clauses proven`);
      }
    }

    // Run reality probe if enabled
    let realityResult: import('@isl-lang/reality-probe').RealityProbeResult | undefined;
    if (options.reality) {
      spinner.text = 'Running reality probe...';
      try {
        const { runRealityProbe } = await import('@isl-lang/reality-probe');
        
        // Auto-detect truthpack paths if not provided
        const routeMapPath = options.realityRouteMap || 
          (existsSync('.shipgate/truthpack/routes.json') ? '.shipgate/truthpack/routes.json' : undefined);
        const envVarsPath = options.realityEnvVars || 
          (existsSync('.shipgate/truthpack/env.json') ? '.shipgate/truthpack/env.json' : undefined);

        if (!options.realityBaseUrl && !routeMapPath && !envVarsPath) {
          spinner.warn('Reality probe skipped: no baseUrl, routeMap, or envVars provided');
        } else {
          realityResult = await runRealityProbe({
            baseUrl: options.realityBaseUrl,
            routeMapPath,
            envVarsPath,
            timeoutMs: timeout,
            verbose: options.verbose,
          });

          if (options.verbose) {
            const { summary } = realityResult;
            spinner.info(
              `Reality: ${summary.existingRoutes}/${summary.totalRoutes} routes exist, ` +
              `${summary.ghostRoutes} ghost routes, ${summary.ghostEnvVars} ghost env vars`
            );
          }
        }
      } catch (error) {
        spinner.warn(`Reality probe failed: ${error instanceof Error ? error.message : String(error)}`);
        // Don't fail verification if reality probe fails
      }
    }

    // Run verification
    spinner.text = 'Running verification tests...';
    const verification = await verifyDomain(ast, implSource, {
      runner: {
        timeout,
        verbose: options.verbose,
        // sandbox: options.sandbox, // Not in VerifyOptions
        // sandboxTimeout: options.sandboxTimeout,
        // sandboxMemory: options.sandboxMemory,
        // sandboxEnv: options.sandboxEnv,
      },
    });

    const duration = Date.now() - startTime;
    let passed = verification.trustScore.overall >= minScore;
    
    // Also check PBT result if enabled
    if (options.pbt && pbtResult && !pbtResult.success) {
      passed = false;
    }

    // Also check reality probe result if enabled
    if (options.reality && realityResult && !realityResult.success) {
      passed = false;
    }

    // Calculate evidence score with all verification results (BUG-001 FIX)
    const evidenceScore = calculateEvidenceScore(verification.trustScore, {
      smtResult,
      pbtResult,
      temporalResult,
      realityResult,
    });

    if (passed) {
      spinner.succeed(`Verification passed (${duration}ms)`);
    } else if (options.pbt && pbtResult && !pbtResult.success) {
      spinner.fail(`Verification failed - PBT found ${pbtResult.summary.failedTests} failing tests`);
    } else {
      spinner.fail(`Verification failed - trust score ${verification.trustScore.overall} < ${minScore}`);
    }

    const result: VerifyResult = {
      success: passed,
      specFile: specPath,
      implFile: implPath,
      verification,
      trustScore: verification.trustScore.overall,
      evidenceScore,
      smtResult,
      pbtResult,
      temporalResult,
      errors,
      duration,
    };

    // Write report if requested
    if (options.report) {
      try {
        await writeEvidenceReport(result, options.report);
        if (!options.json && options.format !== 'json') {
          console.log(chalk.gray(`\nEvidence report written to: ${relative(process.cwd(), resolve(options.report))}`));
        }
      } catch (err) {
        const reportError = err instanceof Error ? err.message : String(err);
        console.error(chalk.yellow(`Warning: Failed to write report: ${reportError}`));
      }
    }

    return result;
  } catch (err) {
    spinner.fail('Verification failed');
    errors.push(err instanceof Error ? err.message : String(err));
    
    return {
      success: false,
      specFile: specPath,
      implFile: implPath,
      errors,
      duration: Date.now() - startTime,
    };
  }
}

/**
 * Verify with auto-discovery of specs
 * Main entry point that handles --spec option and auto-discovery
 */
export async function verifyWithDiscovery(options: VerifyOptions): Promise<VerifyResult[]> {
  const specs = await resolveSpec(options.spec);

  // Phase 2: Specless verification when no .isl files but --impl provided
  if (specs.length === 0 && options.impl) {
    try {
      const { runAuthoritativeGate } = await import('@isl-lang/gate');
      const implPath = resolve(options.impl);
      const projectRoot = dirname(existsSync(implPath) ? implPath : process.cwd());
      const gateResult = await runAuthoritativeGate({
        projectRoot,
        spec: '',
        implementation: existsSync(implPath) ? implPath : options.impl,
        specOptional: true,
        dependencyAudit: true,
        writeBundle: false,
        guardrails: options.guardrails,
        guardrailConfigSource: options.guardrailConfigSource ?? null,
        autoGeneratedSpec: options.autoGeneratedSpec,
      });
      const success = gateResult.verdict === 'SHIP';
      return [{
        success,
        specFile: '',
        implFile: options.impl ?? '',
        errors: success ? [] : gateResult.reasons.map(r => r.message),
        duration: gateResult.durationMs ?? 0,
        evidenceScore: {
          overall: gateResult.score,
          confidence: gateResult.confidence,
          totalChecks: gateResult.aggregation.tests.total + gateResult.aggregation.findings.total,
          passedChecks: gateResult.aggregation.tests.passed,
          failedChecks: gateResult.aggregation.tests.failed + gateResult.aggregation.findings.critical + gateResult.aggregation.findings.high,
          recommendation: success ? 'Production Ready' : 'Critical Issues',
          categories: {
            postconditions: { score: 0, passed: 0, failed: 0, total: 0, weight: 0 },
            invariants: { score: 0, passed: 0, failed: 0, total: 0, weight: 0 },
            scenarios: { score: 0, passed: 0, failed: 0, total: 0, weight: 0 },
            temporal: { score: 0, passed: 0, failed: 0, total: 0, weight: 0 },
          },
        },
      }];
    } catch (err) {
      return [{
        success: false,
        specFile: '',
        implFile: options.impl ?? '',
        errors: [err instanceof Error ? err.message : String(err)],
        duration: 0,
      }];
    }
  }

  if (specs.length === 0) {
    console.error(chalk.red('No ISL spec files found'));
    console.log(chalk.gray('Searched in: .shipgate/specs/*.isl, specs/*.isl, *.isl'));
    console.log(chalk.gray('Use --spec <path> to specify a spec file, or --impl <path> for specless verification'));
    return [{
      success: false,
      specFile: '',
      implFile: options.impl ?? '',
      errors: ['No ISL spec files found'],
      duration: 0,
    }];
  }

  const results: VerifyResult[] = [];
  
  for (const spec of specs) {
    const result = await verify(spec, options);
    results.push(result);
  }

  return results;
}

// ─────────────────────────────────────────────────────────────────────────────
// Output Formatting
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Format a recommendation string
 */
function formatRecommendation(rec: string): string {
  const map: Record<string, string> = {
    production_ready: 'Production Ready',
    staging_recommended: 'Staging Recommended',
    shadow_mode: 'Shadow Mode',
    not_ready: 'Not Ready',
    critical_issues: 'Critical Issues',
  };
  return map[rec] ?? rec;
}

/**
 * Print a category score bar
 */
function printCategoryBar(name: string, score: { score: number; passed: number; total: number }): void {
  const color = score.score >= 100 ? chalk.green
    : score.score >= 80 ? chalk.cyan
    : score.score >= 60 ? chalk.yellow
    : chalk.red;
  
  const barWidth = 20;
  const filled = Math.floor((score.score / 100) * barWidth);
  const bar = chalk.green('█'.repeat(filled)) + chalk.gray('░'.repeat(barWidth - filled));
  
  console.log(`  ${name.padEnd(15)} ${bar} ${color(`${score.passed}/${score.total}`)}`);
}

/**
 * Print evidence score summary
 */
function printEvidenceScore(evidence: EvidenceScore): void {
  console.log('');
  console.log(chalk.bold.cyan('┌─────────────────────────────────────────────┐'));
  console.log(chalk.bold.cyan('│           EVIDENCE SCORE SUMMARY            │'));
  console.log(chalk.bold.cyan('└─────────────────────────────────────────────┘'));
  console.log('');
  
  // Overall score with color
  const scoreColor = evidence.overall >= 95 ? chalk.green
    : evidence.overall >= 85 ? chalk.cyan
    : evidence.overall >= 70 ? chalk.yellow
    : chalk.red;
  
  console.log(chalk.bold('  Evidence Score: ') + scoreColor.bold(`${evidence.overall}/100`));
  console.log(chalk.bold('  Confidence:     ') + chalk.gray(`${evidence.confidence}%`));
  console.log('');
  
  // Pass rate
  const passRate = evidence.totalChecks > 0 
    ? Math.round((evidence.passedChecks / evidence.totalChecks) * 100) 
    : 0;
  console.log(chalk.bold('  Checks: ') + 
    chalk.green(`${evidence.passedChecks} passed`) + 
    chalk.gray(' / ') +
    (evidence.failedChecks > 0 ? chalk.red(`${evidence.failedChecks} failed`) : chalk.gray('0 failed')) +
    chalk.gray(` (${passRate}% pass rate)`));
  console.log('');
  
  // Recommendation
  const recColor = evidence.recommendation.includes('Production Ready') ? chalk.green
    : evidence.recommendation.includes('Staging') ? chalk.cyan
    : evidence.recommendation.includes('Shadow') ? chalk.yellow
    : chalk.red;
  
  console.log(chalk.bold('  Recommendation: ') + recColor(evidence.recommendation));
}

/**
 * Print verify results to console
 * Secrets are automatically masked in output.
 */
export async function printVerifyResult(result: VerifyResult, options?: { detailed?: boolean; format?: string; json?: boolean }): Promise<void> {
  // JSON output (secrets are automatically masked)
  if (options?.json || options?.format === 'json') {
    console.log(safeJSONStringify({
      success: result.success,
      specFile: result.specFile,
      implFile: result.implFile,
      evidenceScore: result.evidenceScore ? {
        overall: result.evidenceScore.overall,
        confidence: result.evidenceScore.confidence,
        recommendation: result.evidenceScore.recommendation,
        passedChecks: result.evidenceScore.passedChecks,
        failedChecks: result.evidenceScore.failedChecks,
        totalChecks: result.evidenceScore.totalChecks,
        categories: result.evidenceScore.categories,
      } : null,
      trustScore: result.trustScore,
      duration: result.duration,
      verification: result.verification ? {
        trustScore: result.verification.trustScore,
        testResult: result.verification.testResult,
      } : null,
      smtResult: result.smtResult ? {
        success: result.smtResult.success,
        summary: result.smtResult.summary,
        checks: result.smtResult.checks,
        duration: result.smtResult.duration,
      } : null,
      pbtResult: result.pbtResult ? {
        success: result.pbtResult.success,
        summary: result.pbtResult.summary,
        behaviors: result.pbtResult.behaviors,
        config: result.pbtResult.config,
        duration: result.pbtResult.duration,
      } : null,
      temporalResult: result.temporalResult ? {
        success: result.temporalResult.success,
        summary: result.temporalResult.summary,
        clauses: result.temporalResult.clauses.map(c => ({
          clauseId: c.clauseId,
          type: c.type,
          clauseText: c.clauseText,
          verdict: c.verdict,
          success: c.success,
          timing: c.timing,
          error: c.error,
        })),
        duration: result.temporalResult.duration,
      } : null,
      realityResult: result.realityResult ? {
        success: result.realityResult.success,
        summary: result.realityResult.summary,
        routes: result.realityResult.routes,
        envVars: result.realityResult.envVars,
        duration: result.realityResult.durationMs,
      } : null,
      errors: result.errors,
    }, undefined, 2));
    return;
  }

  console.log('');

  // Print files
  console.log(chalk.gray('Spec:') + ` ${relative(process.cwd(), result.specFile)}`);
  console.log(chalk.gray('Impl:') + ` ${relative(process.cwd(), result.implFile)}`);
  console.log('');

  // Handle errors
  if (result.errors.length > 0) {
    console.log(chalk.red('✗ Verification failed'));
    console.log('');
    for (const error of result.errors) {
      console.log(chalk.red(`  ${error}`));
    }
    return;
  }

  if (!result.verification) {
    return;
  }

  const { trustScore, testResult } = result.verification;

  // Print evidence score summary
  if (result.evidenceScore) {
    printEvidenceScore(result.evidenceScore);
    console.log('');
  }

  // Trust Score Header
  const scoreColor = trustScore.overall >= 95 ? chalk.green
    : trustScore.overall >= 85 ? chalk.cyan
    : trustScore.overall >= 70 ? chalk.yellow
    : chalk.red;

  console.log(chalk.bold('Trust Score: ') + scoreColor(`${trustScore.overall}/100`));
  console.log(chalk.gray(`Confidence: ${trustScore.confidence}%`));
  console.log('');

  // Recommendation
  const recColor = trustScore.recommendation === 'production_ready' ? chalk.green
    : trustScore.recommendation === 'staging_recommended' ? chalk.cyan
    : trustScore.recommendation === 'shadow_mode' ? chalk.yellow
    : chalk.red;
  
  console.log(chalk.bold('Recommendation: ') + recColor(formatRecommendation(trustScore.recommendation)));
  console.log('');

  // Breakdown
  if (trustScore.breakdown) {
    console.log(chalk.bold('Breakdown:'));
    printCategoryBar('Postconditions', trustScore.breakdown.postconditions);
    printCategoryBar('Invariants', trustScore.breakdown.invariants);
    printCategoryBar('Scenarios', trustScore.breakdown.scenarios);
    printCategoryBar('Temporal', trustScore.breakdown.temporal);
    console.log('');
  }

  // Test Summary
  console.log(chalk.bold('Test Results:'));
  console.log(chalk.green(`  ✓ ${testResult.passed} passed`));
  if (testResult.failed > 0) {
    console.log(chalk.red(`  ✗ ${testResult.failed} failed`));
  }
  if (testResult.skipped > 0) {
    console.log(chalk.yellow(`  ○ ${testResult.skipped} skipped`));
  }
  console.log(chalk.gray(`  Duration: ${testResult.duration}ms`));

  // SMT Results (if available)
  if (result.smtResult) {
    console.log('');
    printSMTResults(result.smtResult, options?.detailed);
  }

  // PBT Results (if available)
  if (result.pbtResult) {
    console.log('');
    printPBTResults(result.pbtResult, options?.detailed);
  }

  // Temporal Results (if available)
  if (result.temporalResult) {
    console.log('');
    printTemporalResults(result.temporalResult, options?.detailed);
  }

  // Detailed failures
  if (options?.detailed && trustScore.details) {
    const failures = trustScore.details.filter(d => d.status === 'failed');
    if (failures.length > 0) {
      console.log('');
      console.log(chalk.bold.red('Failures:'));
      for (const failure of failures) {
        const impactColor = failure.impact === 'critical' ? chalk.red
          : failure.impact === 'high' ? chalk.yellow
          : chalk.gray;
        console.log(`  ${chalk.red('✗')} ${failure.name}`);
        console.log(`    ${impactColor(`[${failure.impact}]`)} ${failure.message ?? ''}`);
      }
    }
  }

  // Unknown clauses with remediation (if verification result has unknown reasons)
  if (result.verification && 'unknownReasons' in result.verification) {
    const verificationResult = result.verification as { unknownReasons?: unknown[] };
    if (verificationResult.unknownReasons && verificationResult.unknownReasons.length > 0) {
      try {
        const { formatUnknownSummary } = await import('@isl-lang/verify-pipeline') as any;
        const unknownOutput = formatUnknownSummary(verificationResult, {
          colors: true,
          detailed: options?.detailed,
        });
        if (unknownOutput) {
          console.log(unknownOutput);
        }
      } catch {
        // Fallback if formatter not available
        console.log('');
        console.log(chalk.yellow(`? ${verificationResult.unknownReasons.length} unknown clause(s)`));
      }
    }
  }

  // Summary line
  console.log('');
  if (result.success) {
    console.log(chalk.green(`✓ Verification passed`));
  } else {
    console.log(chalk.red(`✗ Verification failed`));
  }
  console.log(chalk.gray(`  Completed in ${result.duration}ms`));
}

/**
 * Print SMT verification results
 */
function printSMTResults(smtResult: SMTVerifyResult, detailed?: boolean): void {
  console.log(chalk.bold('SMT Verification:'));
  
  const { summary } = smtResult;
  
  // Summary line
  if (summary.sat > 0) {
    console.log(chalk.green(`  ✓ ${summary.sat} satisfiable`));
  }
  if (summary.unsat > 0) {
    console.log(chalk.red(`  ✗ ${summary.unsat} unsatisfiable`));
  }
  if (summary.unknown > 0) {
    console.log(chalk.yellow(`  ? ${summary.unknown} unknown`));
  }
  if (summary.timeout > 0) {
    console.log(chalk.yellow(`  ⏱ ${summary.timeout} timeout`));
  }
  if (summary.error > 0) {
    console.log(chalk.red(`  ⚠ ${summary.error} error`));
  }
  console.log(chalk.gray(`  Duration: ${smtResult.duration}ms`));
  
  // Detailed checks
  if (detailed && smtResult.checks.length > 0) {
    console.log('');
    console.log(chalk.gray('  Individual checks:'));
    for (const check of smtResult.checks) {
      const statusIcon = check.status === 'sat' ? chalk.green('✓') :
                        check.status === 'unsat' ? chalk.red('✗') :
                        check.status === 'unknown' ? chalk.yellow('?') :
                        check.status === 'timeout' ? chalk.yellow('⏱') :
                        chalk.red('⚠');
      const kindLabel = check.kind === 'precondition_satisfiability' ? 'pre' :
                       check.kind === 'postcondition_implication' ? 'post' :
                       'type';
      console.log(`    ${statusIcon} [${kindLabel}] ${check.name} (${check.duration}ms)`);
      if (check.message) {
        console.log(chalk.gray(`        ${check.message}`));
      }
    }
  }
}

/**
 * Print PBT verification results
 */
function printPBTResults(pbtResult: PBTVerifyResultType, detailed?: boolean): void {
  console.log(chalk.bold('Property-Based Testing:'));
  
  const { summary } = pbtResult;
  
  // Summary line
  console.log(chalk.green(`  ✓ ${summary.passedTests} tests passed`));
  if (summary.failedTests > 0) {
    console.log(chalk.red(`  ✗ ${summary.failedTests} tests failed`));
  }
  console.log(chalk.gray(`  Behaviors: ${summary.passedBehaviors}/${summary.totalBehaviors}`));
  console.log(chalk.gray(`  Duration: ${pbtResult.duration}ms`));
  
  if (pbtResult.config.seed !== undefined) {
    console.log(chalk.gray(`  Seed: ${pbtResult.config.seed}`));
  }

  // Detailed behavior results
  if (detailed && pbtResult.behaviors.length > 0) {
    console.log('');
    console.log(chalk.gray('  Behaviors:'));
    for (const behavior of pbtResult.behaviors) {
      const statusIcon = behavior.success ? chalk.green('✓') : chalk.red('✗');
      console.log(`    ${statusIcon} ${behavior.behaviorName}: ${behavior.testsPassed}/${behavior.testsRun}`);
      
      if (behavior.error) {
        console.log(chalk.red(`        Error: ${behavior.error}`));
      }
      
      for (const violation of behavior.violations) {
        console.log(chalk.red(`        [${violation.type}] ${violation.property}`));
        console.log(chalk.gray(`          ${violation.error}`));
      }
    }
  }

  // Reproduction hint
  if (!pbtResult.success && pbtResult.config.seed !== undefined) {
    console.log('');
    console.log(chalk.gray(`  To reproduce: isl verify --pbt --pbt-seed ${pbtResult.config.seed}`));
  }
}

/**
 * Print temporal verification results
 */
function printTemporalResults(temporalResult: TemporalVerifyResult, detailed?: boolean): void {
  console.log(chalk.bold('Temporal Verification:'));
  
  const { summary } = temporalResult;
  
  // Summary line with color-coded verdicts
  if (summary.proven > 0) {
    console.log(chalk.green(`  ✓ ${summary.proven} clauses proven`));
  }
  if (summary.notProven > 0) {
    console.log(chalk.red(`  ✗ ${summary.notProven} clauses not proven`));
  }
  if (summary.incomplete > 0) {
    console.log(chalk.yellow(`  ? ${summary.incomplete} clauses incomplete (need more samples)`));
  }
  if (summary.unknown > 0) {
    console.log(chalk.gray(`  - ${summary.unknown} clauses unknown`));
  }
  console.log(chalk.gray(`  Duration: ${temporalResult.duration}ms`));
  
  // Temporal clause table
  if (detailed && temporalResult.clauses.length > 0) {
    console.log('');
    console.log(chalk.gray('  Temporal Clause Results:'));
    console.log(chalk.gray('  ┌──────┬────────────────────────────────────┬───────────────────┬──────────────┐'));
    console.log(chalk.gray('  │ STAT │ CLAUSE                             │ VERDICT           │ TIMING       │'));
    console.log(chalk.gray('  ├──────┼────────────────────────────────────┼───────────────────┼──────────────┤'));
    
    for (const clause of temporalResult.clauses) {
      const statusIcon = clause.success ? chalk.green('✓') : 
                        clause.verdict === 'INCOMPLETE_PROOF' ? chalk.yellow('?') : 
                        chalk.red('✗');
      
      const verdictColor = clause.verdict === 'PROVEN' ? chalk.green :
                          clause.verdict === 'NOT_PROVEN' ? chalk.red :
                          clause.verdict === 'INCOMPLETE_PROOF' ? chalk.yellow :
                          chalk.gray;
      
      // Truncate clause text to fit table
      const clauseText = clause.clauseText.length > 34 
        ? clause.clauseText.substring(0, 31) + '...'
        : clause.clauseText.padEnd(34);
      
      const verdict = verdictColor(clause.verdict.padEnd(17));
      
      let timing = '';
      if (clause.timing?.actualMs !== undefined) {
        timing = `${clause.timing.actualMs.toFixed(1)}ms`;
        if (clause.timing.percentile) {
          timing += ` (p${clause.timing.percentile})`;
        }
      } else if (clause.timing?.sampleCount === 0) {
        timing = 'no samples';
      }
      timing = timing.padEnd(12);
      
      console.log(chalk.gray(`  │  ${statusIcon}   │ `) + clauseText + chalk.gray(' │ ') + verdict + chalk.gray(' │ ') + timing + chalk.gray(' │'));
    }
    
    console.log(chalk.gray('  └──────┴────────────────────────────────────┴───────────────────┴──────────────┘'));
    
    // Show errors for failed clauses
    const failedClauses = temporalResult.clauses.filter(c => !c.success && c.error);
    if (failedClauses.length > 0) {
      console.log('');
      console.log(chalk.gray('  Errors:'));
      for (const clause of failedClauses) {
        console.log(chalk.red(`    ${clause.clauseId}: ${clause.error}`));
      }
    }
  }
}

/**
 * Get exit code for verify result
 */
export function getVerifyExitCode(result: VerifyResult): number {
  return result.success ? 0 : 1;
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — Types
// ─────────────────────────────────────────────────────────────────────────────

/** Verification mode auto-detected from file structure */
export type VerificationMode = 'isl' | 'specless' | 'mixed';

/** Strictness level for --fail-on */
export type FailOnLevel = 'error' | 'warning' | 'unspecced';

/** Overall verification verdict */
export type UnifiedVerdict = 'SHIP' | 'NO_SHIP' | 'WARN';

/** File-level verification status */
export type FileVerifyStatus = 'PASS' | 'WARN' | 'FAIL';

/** How a file was verified */
export type FileVerifyMode = 'ISL verified' | 'Specless' | 'Fake feature' | 'Skipped';

/** How the ISL spec was sourced */
export type SpecSource = 'hand-written' | 'inferred' | 'ai-assisted';

/** Output format options */
export type OutputFormat = 'json' | 'text' | 'gitlab' | 'junit' | 'github';

/** Options for the unified verify command */
export interface UnifiedVerifyOptions {
  /** Explicit ISL spec file (enables legacy single-spec mode) */
  spec?: string;
  /** Explicit implementation file */
  impl?: string;
  /** Output JSON to stdout */
  json?: boolean;
  /** CI mode with sensible defaults */
  ci?: boolean;
  /** Output format: json, text, gitlab, junit, github */
  format?: OutputFormat;
  /** Strictness level (default: 'error') */
  failOn?: FailOnLevel;
  /** Verbose output */
  verbose?: boolean;
  /** Minimum trust score to consider PASS (default: 70) */
  minScore?: number;
  /** Show detailed breakdown */
  detailed?: boolean;
  /** Evidence report output path */
  report?: string;
  /** Test timeout in ms (default: 30000) */
  timeout?: number;
  /** Generate explain reports */
  explain?: boolean;
  /** Suppress per-file spinner output when running batch verification */
  quiet?: boolean;
  /** ShipGate config for ci.ignore filtering (applied before verification) */
  shipgateConfig?: import('../config/schema.js').ShipGateConfig;
  /** Guardrail policy overrides (from .shipgate.yml) */
  guardrails?: {
    allowAutoSpecShip?: boolean;
    allowNoTestExecution?: boolean;
    allowEmptyCategories?: boolean;
    allowUnvalidatedAiRules?: boolean;
  };
  /** Path to the config file that set guardrail overrides (for audit trail) */
  guardrailConfigSource?: string | null;
  /** Report spec coverage (files with specs, auto-specced, unspecced) */
  specCoverage?: boolean;
  /** Use tiered trust score weighting (Tier 1=3x, Tier 2=2x, Tier 3=1x) */
  useTieredScoring?: boolean;
}

/** Verification tier: 1=strict, 2=standard, 3=relaxed */
export type VerificationTier = 1 | 2 | 3;

/** Per-file verification result */
export interface FileVerifyResultEntry {
  /** Relative file path */
  file: string;
  /** PASS / WARN / FAIL */
  status: FileVerifyStatus;
  /** How this file was verified */
  mode: FileVerifyMode;
  /** Normalized score 0.00 - 1.00 */
  score: number;
  /** Verification tier (1=strict, 2=standard, 3=relaxed) */
  tier?: VerificationTier;
  /** Which ISL spec verified this file (if any) */
  specFile?: string;
  /** How the spec was sourced */
  specSource?: SpecSource;
  /** Spec generation confidence 0.00 - 1.00 (for inferred/ai-assisted) */
  specConfidence?: number;
  /** Number of tests that actually executed */
  testsExecuted?: number;
  /** Total number of tests expected */
  testsTotal?: number;
  /** Human-readable blocker messages */
  blockers: string[];
  /** Errors encountered */
  errors: string[];
  /** Duration in ms */
  duration: number;
}

/** Proof bundle evidence entry for audit trail */
export interface ProofEvidence {
  source: 'isl-spec' | 'static-analysis' | 'test-execution' | 'inference' | 'ai-assisted';
  check: string;
  result: 'pass' | 'fail' | 'warn' | 'skip' | 'gap';
  confidence: number;
  details: string;
}

/** Proof bundle metadata for skeptical-engineer audit */
export interface ProofBundle {
  /** All evidence entries from verification */
  evidence: ProofEvidence[];
  /** Explicit gaps in verification coverage */
  gaps: ProofGap[];
  /** Confidence budget breakdown */
  confidenceBudget: {
    specConfidence: number;
    testExecutionRate: number;
    coverageRate: number;
    overallConfidence: number;
  };
  /** Risk acceptances (guardrail overrides active) */
  riskAcceptances: string[];
  /** Whether the proof is sufficient for SHIP */
  sufficient: boolean;
}

/** Spec coverage report: files with specs, auto-specced, unspecced */
export interface SpecCoverageReport {
  /** Files with hand-written ISL specs */
  withSpecs: string[];
  /** Files with auto-generated specs */
  autoSpecced: string[];
  /** Files without any spec */
  unspecced: string[];
}

/** An explicit gap in verification coverage */
export interface ProofGap {
  file: string;
  category: 'missing-spec' | 'missing-tests' | 'missing-postcondition' | 'missing-error-case' | 'low-confidence' | 'tests-not-executed';
  description: string;
  severity: 'critical' | 'high' | 'medium';
}

/** Overall unified verification result */
export interface UnifiedVerifyResult {
  /** SHIP / NO_SHIP / WARN */
  verdict: UnifiedVerdict;
  /** Overall score 0.00 - 1.00 */
  score: number;
  /** Trust score 0–100 (score * 100) */
  trustScore: number;
  /** Confidence 0.00 - 1.00 */
  confidence: number;
  /** Evidence summary string, e.g. "tests executed: 18/18" */
  evidence: string;
  /** Coverage gaps identified */
  gaps: string[];
  /** Spec source breakdown */
  specSources: { 'hand-written': number; inferred: number; 'ai-assisted': number };
  /** Top reasons for the verdict (max 3) */
  why: string[];
  /** ISL spec coverage */
  coverage: { specced: number; total: number };
  /** Spec coverage report (files with specs, auto-specced, unspecced) */
  specCoverage?: SpecCoverageReport;
  /** Per-file results */
  files: FileVerifyResultEntry[];
  /** Aggregated blockers */
  blockers: string[];
  /** Suggested next steps */
  recommendations: string[];
  /** Detected verification mode */
  mode: VerificationMode;
  /** Total duration in ms */
  duration: number;
  /** Process exit code */
  exitCode: number;
  /** Proof bundle for audit trail — surfaces evidence, gaps, confidence, risk */
  proofBundle?: ProofBundle;
}

/** Detection result from path analysis */
interface ModeDetectionResult {
  mode: VerificationMode;
  islFiles: string[];
  codeFiles: string[];
  /** Map from code file path to its matching ISL spec path */
  specMap: Map<string, string>;
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — Auto-Detection
// ─────────────────────────────────────────────────────────────────────────────

const CODE_EXTENSIONS = ['ts', 'js', 'tsx', 'jsx'];
const CODE_GLOB = `**/*.{${CODE_EXTENSIONS.join(',')}}`;

/** Get ignore patterns from config (config-driven, respects ci.ignore) */
function getIgnorePatterns(config: import('../config/schema.js').ShipGateConfig): string[] {
  const ci = config.ci ?? {};
  return ci.ignore ?? DEFAULT_SHIPGATE_CONFIG.ci!.ignore!;
}

/**
 * Detect verification mode from the target path.
 * Uses config-driven ignore patterns for glob scanning.
 */
/**
 * Segment-based path filter — reliably excludes files on all platforms.
 * Checks each path segment against a blocklist, and also matches
 * filename-level patterns (e.g. *.test.ts, *.config.js).
 * This is a hardened replacement for glob ignore + picomatch which
 * can fail on Windows due to backslash/forward-slash mismatches.
 */
const EXCLUDED_SEGMENTS = new Set([
  'node_modules', 'dist', 'build', '.next', 'coverage', '.turbo',
  '.git', '.shipgate', 'tests', '__tests__', 'test', 'bench',
  'benchmarks', 'fixtures', 'generated', 'vibe-test',
]);

const EXCLUDED_SEGMENT_PREFIXES = ['vibe-test'];

const EXCLUDED_FILE_PATTERNS = [
  /\.test\.[tj]sx?$/,
  /\.spec\.[tj]sx?$/,
  /\.config\.[tj]sx?$/,
  /\.config\.mjs$/,
  /\.min\.[tj]s$/,
  /\.bundle\.js$/,
  /\.generated\./,
  /\.snap$/,
  /\.map$/,
];

function isExcludedPath(relPath: string): boolean {
  const segments = relPath.split(/[/\\]/);
  for (const seg of segments) {
    if (EXCLUDED_SEGMENTS.has(seg)) return true;
    for (const prefix of EXCLUDED_SEGMENT_PREFIXES) {
      if (seg.startsWith(prefix)) return true;
    }
  }
  const filename = segments[segments.length - 1];
  for (const pat of EXCLUDED_FILE_PATTERNS) {
    if (pat.test(filename)) return true;
  }
  return false;
}

async function detectVerificationMode(
  targetPath: string,
  config: import('../config/schema.js').ShipGateConfig,
): Promise<ModeDetectionResult> {
  const absTarget = resolve(targetPath);
  const ignorePatterns = getIgnorePatterns(config);
  const isIgnored = picomatch(ignorePatterns, { dot: true, bash: true });

  // 1. Find code files in the target directory (config-driven ignore)
  let codeFiles = await glob(CODE_GLOB, {
    cwd: absTarget,
    ignore: ignorePatterns,
    absolute: true,
    dot: true,
    posix: true,
  });
  // Post-filter: segment-based exclusion (reliable on Windows)
  codeFiles = codeFiles.filter((f) => {
    const rel = relative(absTarget, f);
    const relFwd = rel.replace(/\\/g, '/');
    return !isExcludedPath(rel) && !isIgnored(relFwd);
  });

  // 2. Find ISL files: in the target, specs/, and .shipgate/specs/
  let islInTarget = await glob('**/*.isl', {
    cwd: absTarget,
    ignore: ignorePatterns,
    absolute: true,
    dot: true,
    posix: true,
  });
  islInTarget = islInTarget.filter((f) => {
    const rel = relative(absTarget, f);
    const relFwd = rel.replace(/\\/g, '/');
    return !isExcludedPath(rel) && !isIgnored(relFwd);
  });

  // Also check standard spec locations relative to the target
  const specDirs = [
    resolve(absTarget, 'specs'),
    resolve(absTarget, '.shipgate/specs'),
    resolve(absTarget, '../specs'),
    resolve(absTarget, '../.shipgate/specs'),
  ];

  const externalSpecs: string[] = [];
  for (const dir of specDirs) {
    if (existsSync(dir)) {
      const found = await glob('**/*.isl', {
        cwd: dir,
        ignore: ignorePatterns,
        absolute: true,
        dot: true,
        posix: true,
      });
      externalSpecs.push(...found);
    }
  }

  const allIslFiles = [...new Set([...islInTarget, ...externalSpecs])];

  // 3. Build spec-to-code mapping by filename convention
  const specMap = new Map<string, string>();

  for (const codeFile of codeFiles) {
    const codeBase = basename(codeFile).replace(/\.[^.]+$/, '');
    
    // Try to find a matching ISL spec by name
    const matchingSpec = allIslFiles.find(islFile => {
      const islBase = basename(islFile, '.isl');
      return (
        islBase === codeBase ||
        islBase === codeBase.replace(/\.impl$/, '') ||
        islBase.toLowerCase() === codeBase.toLowerCase()
      );
    });

    if (matchingSpec) {
      specMap.set(codeFile, matchingSpec);
    }
  }

  // 4. Determine mode
  let mode: VerificationMode;
  if (allIslFiles.length === 0) {
    mode = 'specless';
  } else if (specMap.size >= codeFiles.length && codeFiles.length > 0) {
    mode = 'isl';
  } else if (specMap.size > 0) {
    mode = 'mixed';
  } else if (allIslFiles.length > 0 && codeFiles.length === 0) {
    mode = 'isl';
  } else {
    mode = 'specless';
  }

  return { mode, islFiles: allIslFiles, codeFiles, specMap };
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — Auto Spec Generation for Unspecced Files
// ─────────────────────────────────────────────────────────────────────────────

// ── Signature extraction types ───────────────────────────────────────────────

interface ExtractedParam {
  name: string;
  type: string;
}

interface ExtractedFunction {
  name: string;
  isAsync: boolean;
  params: ExtractedParam[];
  returnType: string;
  throws: string[];
  effects: string[];
}

/**
 * Map a TypeScript type annotation to the closest ISL primitive.
 */
function tsTypeToIsl(tsType: string): string {
  const trimmed = tsType.trim();
  if (!trimmed || trimmed === 'any' || trimmed === 'unknown') return 'String';
  if (trimmed === 'string') return 'String';
  if (trimmed === 'number' || trimmed === 'bigint') return 'Int';
  if (trimmed === 'boolean') return 'Boolean';
  if (trimmed === 'void' || trimmed === 'undefined' || trimmed === 'never') return 'Void';
  if (trimmed === 'null') return 'Void';
  if (trimmed.endsWith('[]') || trimmed.startsWith('Array<')) return 'List';
  if (trimmed.startsWith('Promise<')) {
    const inner = trimmed.slice(8, -1);
    return tsTypeToIsl(inner);
  }
  if (trimmed.startsWith('Record<') || trimmed.startsWith('Map<') || trimmed === 'object') return 'Map';
  if (trimmed === 'Date') return 'DateTime';
  if (trimmed === 'Buffer' || trimmed === 'Uint8Array') return 'Bytes';
  // For named types (interfaces, classes), preserve the name as-is
  if (/^[A-Z]\w*$/.test(trimmed)) return trimmed;
  // Union/intersection or complex types → String fallback
  return 'String';
}

/**
 * Extract function signatures with full type information from TS/JS source.
 */
function extractSignatures(source: string): {
  functions: ExtractedFunction[];
  types: string[];
} {
  const functions: ExtractedFunction[] = [];
  const types: string[] = [];

  // Extract exported function signatures with full param/return type info
  const fnFullRegex = /export\s+(async\s+)?function\s+(\w+)\s*(?:<[^>]*>)?\s*\(([^)]*)\)\s*(?::\s*([^{]+?))?\s*\{/g;
  let match: RegExpExecArray | null;
  const seenFns = new Set<string>();

  while ((match = fnFullRegex.exec(source)) !== null) {
    const isAsync = !!match[1];
    const name = match[2];
    if (seenFns.has(name)) continue;
    seenFns.add(name);

    const rawParams = match[3].trim();
    const rawReturn = match[4]?.trim() ?? '';
    const params = parseParamList(rawParams);
    const returnType = rawReturn ? tsTypeToIsl(rawReturn) : (isAsync ? 'String' : 'Void');

    // Extract the function body for throws/effects analysis
    const fnStart = match.index! + match[0].length - 1;
    const fnBody = extractBracedBlock(source, fnStart);

    const throws = detectThrows(fnBody);
    const effects = detectEffects(fnBody);

    functions.push({ name, isAsync, params, returnType, throws, effects });
  }

  // Fallback: non-exported functions if nothing exported
  if (functions.length === 0) {
    const anyFnRegex = /(async\s+)?function\s+(\w+)\s*(?:<[^>]*>)?\s*\(([^)]*)\)\s*(?::\s*([^{]+?))?\s*\{/g;
    while ((match = anyFnRegex.exec(source)) !== null) {
      const isAsync = !!match[1];
      const name = match[2];
      if (seenFns.has(name)) continue;
      seenFns.add(name);

      const rawParams = match[3].trim();
      const rawReturn = match[4]?.trim() ?? '';
      const params = parseParamList(rawParams);
      const returnType = rawReturn ? tsTypeToIsl(rawReturn) : (isAsync ? 'String' : 'Void');

      const fnStart = match.index! + match[0].length - 1;
      const fnBody = extractBracedBlock(source, fnStart);
      const throws = detectThrows(fnBody);
      const effects = detectEffects(fnBody);

      functions.push({ name, isAsync, params, returnType, throws, effects });
    }
  }

  // Extract type/interface/class names
  const typeRegex = /export\s+(?:interface|class|type)\s+(\w+)/g;
  while ((match = typeRegex.exec(source)) !== null) {
    types.push(match[1]);
  }
  if (types.length === 0) {
    const anyTypeRegex = /(?:interface|class)\s+(\w+)/g;
    while ((match = anyTypeRegex.exec(source)) !== null) {
      types.push(match[1]);
    }
  }

  return { functions, types };
}

/**
 * Parse a comma-separated param list into name+type pairs.
 */
function parseParamList(raw: string): ExtractedParam[] {
  if (!raw) return [];
  const params: ExtractedParam[] = [];
  // Split on commas that are not inside angle brackets or parens
  let depth = 0;
  let current = '';
  for (const ch of raw) {
    if (ch === '<' || ch === '(' || ch === '{' || ch === '[') depth++;
    else if (ch === '>' || ch === ')' || ch === '}' || ch === ']') depth--;
    else if (ch === ',' && depth === 0) {
      params.push(parseOneParam(current.trim()));
      current = '';
      continue;
    }
    current += ch;
  }
  if (current.trim()) params.push(parseOneParam(current.trim()));
  return params.filter((p) => p.name && p.name !== '');
}

function parseOneParam(raw: string): ExtractedParam {
  // Handle destructured params: { a, b }: Type
  if (raw.startsWith('{')) {
    const colonIdx = raw.lastIndexOf(':');
    if (colonIdx > raw.indexOf('}')) {
      return { name: 'options', type: tsTypeToIsl(raw.slice(colonIdx + 1).trim()) };
    }
    return { name: 'options', type: 'Map' };
  }
  // Handle rest params: ...args: Type[]
  if (raw.startsWith('...')) {
    raw = raw.slice(3);
  }
  // name?: Type or name: Type or name = default
  const optional = raw.includes('?:');
  const parts = raw.split(/\??:/);
  const name = parts[0].split('=')[0].trim();
  let type = 'String';
  if (parts.length > 1) {
    type = tsTypeToIsl(parts[1].split('=')[0].trim());
  }
  if (optional) type += '?';
  return { name, type };
}

/**
 * Extract a brace-delimited block starting at the given index.
 */
function extractBracedBlock(source: string, startIdx: number): string {
  if (source[startIdx] !== '{') return '';
  let depth = 0;
  let end = startIdx;
  for (let i = startIdx; i < source.length && i < startIdx + 5000; i++) {
    if (source[i] === '{') depth++;
    else if (source[i] === '}') {
      depth--;
      if (depth === 0) { end = i; break; }
    }
  }
  return source.slice(startIdx, end + 1);
}

/**
 * Detect throw statements and infer error types from a function body.
 */
function detectThrows(body: string): string[] {
  const throws: string[] = [];
  const seen = new Set<string>();

  // throw new ErrorType(...)
  const throwNewRegex = /throw\s+new\s+(\w+)/g;
  let m: RegExpExecArray | null;
  while ((m = throwNewRegex.exec(body)) !== null) {
    const name = m[1];
    if (!seen.has(name)) { seen.add(name); throws.push(name); }
  }

  // throw expression (non-new)
  if (throws.length === 0 && /throw\s+(?!new\b)/.test(body)) {
    throws.push('Error');
  }

  return throws;
}

/**
 * Detect side effects from a function body.
 */
function detectEffects(body: string): string[] {
  const effects: string[] = [];

  if (/\bconsole\.\w+\s*\(/.test(body)) effects.push('logging');
  if (/\bfetch\s*\(/.test(body) || /\baxios[\s.]/.test(body) || /\.request\s*\(/.test(body)) effects.push('network');
  if (/\bfs\b|\breadFile\b|\bwriteFile\b|\bmkdir\b|\bunlink\b/.test(body)) effects.push('filesystem');
  if (/\b(?:query|execute|findOne|findMany|insert|update|delete|upsert)\s*\(/.test(body)) effects.push('database');
  if (/\bprocess\.env\b/.test(body)) effects.push('env_read');
  if (/\bprocess\.exit\b/.test(body)) effects.push('process_exit');
  if (/\bemit\s*\(|\bdispatch\s*\(|\bpublish\s*\(/.test(body)) effects.push('event_emit');
  if (/\bsetTimeout\s*\(|\bsetInterval\s*\(/.test(body)) effects.push('timer');
  if (/\bMath\.random\s*\(|\bcrypto\b/.test(body)) effects.push('nondeterminism');

  return effects;
}

/**
 * AI-powered spec generation for low-confidence extractions.
 * Uses @isl-lang/ai-copilot to produce semantic ISL with business logic,
 * error cases, and postconditions beyond what static extraction can infer.
 * Returns null silently if AI is unavailable (no API key, no copilot package).
 */
async function generateSpecWithAI(
  source: string,
  domainName: string,
  functions: ExtractedFunction[],
  types: string[],
): Promise<{ islContent: string; confidence: number } | null> {
  // Resolve API key from env
  const apiKey = process.env['ANTHROPIC_API_KEY'] ?? process.env['ISL_ANTHROPIC_KEY']
    ?? process.env['OPENAI_API_KEY'] ?? process.env['ISL_OPENAI_KEY'];
  if (!apiKey) return null;

  const provider = (process.env['ANTHROPIC_API_KEY'] || process.env['ISL_ANTHROPIC_KEY'])
    ? 'anthropic' : 'openai';

  let ISLCopilot: any;
  try {
    const mod = await import('@isl-lang/ai-copilot');
    ISLCopilot = mod.ISLCopilot;
  } catch {
    return null; // ai-copilot not available
  }

  const copilot = new ISLCopilot({
    provider,
    apiKey,
    maxTokens: 4096,
    temperature: 0.2,
    cacheEnabled: true,
  });

  await copilot.initialize();

  // Build a prompt with extracted signatures as context
  const sigSummary = functions.map(fn => {
    const params = fn.params.map(p => `${p.name}: ${p.type}`).join(', ');
    const ret = fn.returnType || 'void';
    const attrs: string[] = [];
    if (fn.isAsync) attrs.push('async');
    if (fn.throws.length > 0) attrs.push(`throws ${fn.throws.join(', ')}`);
    if (fn.effects.length > 0) attrs.push(`effects: ${fn.effects.join(', ')}`);
    return `  ${fn.isAsync ? 'async ' : ''}function ${fn.name}(${params}): ${ret}${attrs.length ? ' // ' + attrs.join(', ') : ''}`;
  }).join('\n');

  const typesSummary = types.length > 0 ? `Types: ${types.join(', ')}` : '';

  const prompt = `Generate a complete ISL (Intent Specification Language) spec for domain "${domainName}".

Source code signatures:
${sigSummary}
${typesSummary}

Rules:
- Use exact function names as behavior names
- Use exact parameter names and ISL types (String, Int, Boolean, List, Map, Timestamp, Void)
- Include postconditions that describe what each function guarantees on success
- Include invariants that describe what must always be true
- Include error cases from throw statements
- Do NOT invent behaviors that don't exist in the source
- Mark any uncertain inferences with comments
- Output ONLY the ISL spec, no markdown fences

ISL syntax example:
domain Example {
  version: "1.0.0"
  entity User { id: String, email: String }
  behavior createUser {
    input { email: String, password: String }
    output { success: User errors { InvalidEmail { when: "email format invalid" } } }
    postconditions { - createUser returns valid User }
    invariants { - createUser never_throws_unhandled }
  }
}`;

  try {
    const result = await copilot.chat(prompt);
    const content = result?.content?.trim();
    if (!content || content.length < 30) return null;

    // Strip markdown fences if present
    let isl = content;
    const fenceMatch = isl.match(/```(?:\w+)?\n([\s\S]*?)```/);
    if (fenceMatch) isl = fenceMatch[1].trim();

    // Validate through parser
    const parseResult = parseISL(isl, 'ai-generated.isl');
    if (!parseResult.success && parseResult.errors && parseResult.errors.length > 0) {
      return null;
    }

    // AI specs get higher confidence than extraction but still capped
    return { islContent: isl, confidence: 0.65 };
  } catch {
    return null;
  }
}

/**
 * Generate an ISL spec from a source file using the 3-tier inference pipeline.
 *
 * Tier 1: Static signature extraction via TS compiler API (always runs)
 * Tier 2: Semantic rule inference with heuristics (always runs)
 * Tier 3: AI-assisted completion (only when Tier 2 has gaps)
 *
 * The inference engine is FIRST-CLASS — not optional. A regex fallback only
 * exists for the rare case where the pipeline package fails to load.
 */
async function generateSpecFromSource(
  codeFile: string,
): Promise<{ islContent: string; confidence: number } | null> {
  try {
    const ext = codeFile.replace(/.*\./, '.');
    if (!['.ts', '.js', '.tsx', '.jsx'].includes(ext)) return null;

    const domainBase = basename(codeFile).replace(/\.[^.]+$/, '');
    const domainName = domainBase
      .split(/[-_.]/)
      .map((p) => p.charAt(0).toUpperCase() + p.slice(1))
      .join('');

    // ── Primary path: 3-tier inference pipeline ──────────────────────────
    try {
      // Inference module not available - skip
      throw new Error('@isl-lang/inference not available');
      /*const { runPipeline } = await import('@isl-lang/inference');
      const result = await runPipeline({
        sourceFiles: [codeFile],
        domainName,
        tier1: { exportedOnly: false, analyzeBodies: true },
        tier2: { minConfidence: 0.3, temporal: true, security: true },
        tier3: { enabled: false }, // AI only on explicit --ai flag
        includeInvariants: true,
        confidenceThreshold: 0.3,
      });

      if (result.isl && result.isl.trim().length > 20) {
        return { islContent: result.isl, confidence: result.confidence };
      }*/

      // Pipeline ran but produced nothing useful — fall through to legacy
    } catch {
      // Pipeline package not loadable — fall through to regex fallback
    }

    // ── Last-resort fallback: regex extraction ───────────────────────────
    // This only runs if the pipeline package fails to load entirely.
    const source = await readFile(codeFile, 'utf-8');
    const { functions, types } = extractSignatures(source);

    if (functions.length === 0 && types.length === 0) return null;

    let confidence = 0.1;
    if (functions.length > 0) confidence += 0.15;
    if (types.length > 0) confidence += 0.1;
    if (functions.some(f => f.throws.length > 0)) confidence += 0.05;
    if (functions.some(f => f.effects.length > 0)) confidence += 0.05;
    confidence = Math.min(confidence, 0.45);

    const lines: string[] = [];
    lines.push('# STATUS: INCOMPLETE — regex-fallback scaffold (inference engine unavailable)');
    lines.push('');
    lines.push(`domain ${domainName} {`);
    lines.push('  version: "1.0.0"');

    if (types.length > 0) {
      lines.push('');
      for (const t of types) {
        lines.push(`  entity ${t} {`);
        lines.push(`    id: String`);
        lines.push('  }');
      }
    }

    if (functions.length > 0) {
      lines.push('');
      for (const fn of functions) {
        lines.push(`  behavior ${fn.name} {`);
        lines.push('    input {');
        for (const p of fn.params) {
          lines.push(`      ${p.name}: ${p.type}`);
        }
        lines.push('    }');
        lines.push('');
        lines.push('    output {');
        lines.push(`      success: ${fn.returnType}`);
        if (fn.throws.length > 0) {
          lines.push('');
          lines.push('      errors {');
          for (const errName of fn.throws) {
            lines.push(`        ${errName} {`);
            lines.push(`          when: "inferred from throw statement"`);
            lines.push('        }');
          }
          lines.push('      }');
        }
        lines.push('    }');
        lines.push('');
        lines.push('    invariants {');
        lines.push(`      - ${fn.name} never_throws_unhandled`);
        if (fn.isAsync) {
          lines.push(`      - ${fn.name} resolves_or_rejects`);
        }
        lines.push('    }');
        lines.push('  }');
      }
    }

    lines.push('}');
    lines.push('');

    return { islContent: lines.join('\n'), confidence };
  } catch {
    return null;
  }
}

/**
 * Auto-generate ISL specs for unspecced code files.
 * Writes generated specs to .shipgate/generated-specs/ and returns
 * a map from code file path to generated spec path.
 */
interface GeneratedSpecInfo {
  specPath: string;
  confidence: number;
  source: SpecSource;
}

async function autoGenerateSpecs(
  unspeccedFiles: string[],
  projectRoot: string,
): Promise<Map<string, GeneratedSpecInfo>> {
  const generatedMap = new Map<string, GeneratedSpecInfo>();
  const specsDir = join(projectRoot, '.shipgate', 'generated-specs');

  for (const codeFile of unspeccedFiles) {
    // Try AutoSpecGenerator first for utility files (Tier 3)
    let result: { islContent: string; confidence: number } | null = null;
    try {
      const utilResult = await generateUtilitySpec(codeFile);
      if (utilResult?.islContent) {
        result = { islContent: utilResult.islContent, confidence: utilResult.confidence };
      }
    } catch {
      // Fall through to generateSpecFromSource
    }

    if (!result) {
      result = await generateSpecFromSource(codeFile);
    }
    if (!result) continue;

    // Validate the generated ISL through the parser
    const parseResult = parseISL(result.islContent, 'generated.isl');
    if (!parseResult.success && parseResult.errors && parseResult.errors.length > 0) {
      continue; // Skip files with unparseable specs
    }

    // Write spec to .shipgate/generated-specs/<relative-path>.isl
    const relPath = relative(projectRoot, codeFile);
    const specFileName = relPath.replace(/\.[^.]+$/, '.isl').replace(/\\/g, '/');
    const specPath = join(specsDir, specFileName);

    try {
      const specDir = dirname(specPath);
      if (!existsSync(specDir)) {
        await mkdir(specDir, { recursive: true });
      }
      await writeFile(specPath, result.islContent, 'utf-8');
      generatedMap.set(codeFile, {
        specPath,
        confidence: result.confidence,
        source: 'inferred',
      });
    } catch {
      // Skip files we can't write specs for
    }
  }

  return generatedMap;
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — ISL Verification Wrapper
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Run ISL verification on a code file against its matched spec.
 */
async function runISLFileVerification(
  codeFile: string,
  specFile: string,
  options: UnifiedVerifyOptions,
  specMeta?: { source: SpecSource; confidence?: number },
): Promise<FileVerifyResultEntry> {
  const relPath = relative(process.cwd(), codeFile);
  const relSpec = relative(process.cwd(), specFile);

  try {
    const result = await verify(specFile, {
      impl: codeFile,
      timeout: options.timeout ?? 30000,
      minScore: options.minScore ?? 70,
      verbose: options.verbose,
      quiet: options.quiet,
    });

    const score = result.trustScore
      ? Math.round((result.trustScore / 100) * 100) / 100
      : (result.success ? 0.85 : 0.3);

    let status: FileVerifyStatus;
    if (!result.success) {
      status = 'FAIL';
    } else if (score < 0.7) {
      status = 'WARN';
    } else {
      status = 'PASS';
    }

    const blockers: string[] = [];
    if (!result.success && result.verification) {
      const failures = result.verification.trustScore.details.filter(
        (d: { status: string }) => d.status === 'failed'
      );
      for (const failure of failures) {
        blockers.push(`${relPath}: ${failure.name} — ${failure.message ?? 'failed'}`);
      }
    }
    if (!result.success && result.errors.length > 0) {
      for (const error of result.errors) {
        blockers.push(`${relPath}: ${error}`);
      }
    }

    // Extract test execution counts from verification result
    const testsExecuted = result.verification?.testResult
      ? result.verification.testResult.passed + result.verification.testResult.failed
      : undefined;
    const testsTotal = result.verification?.testResult
      ? result.verification.testResult.passed + result.verification.testResult.failed + result.verification.testResult.skipped
      : undefined;

    const specContent = await readFile(specFile, 'utf-8').catch(() => '');
    const tier = classifyTier(codeFile, specContent);

    return {
      file: relPath,
      status,
      mode: 'ISL verified',
      score,
      tier,
      specFile: relSpec,
      specSource: specMeta?.source ?? 'hand-written',
      specConfidence: specMeta?.confidence,
      testsExecuted,
      testsTotal,
      blockers,
      errors: result.errors,
      duration: result.duration,
    };
  } catch (err) {
    const tier = classifyTier(codeFile);
    return {
      file: relPath,
      status: 'FAIL',
      tier,
      mode: 'ISL verified',
      score: 0,
      specFile: relSpec,
      specSource: specMeta?.source ?? 'hand-written',
      specConfidence: specMeta?.confidence,
      testsExecuted: 0,
      testsTotal: 0,
      blockers: [`${relPath}: ${err instanceof Error ? err.message : String(err)}`],
      errors: [err instanceof Error ? err.message : String(err)],
      duration: 0,
    };
  }
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — Orchestration
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Calculate the overall verdict from per-file results and options.
 */
function calculateVerdict(
  files: FileVerifyResultEntry[],
  options: UnifiedVerifyOptions,
): UnifiedVerdict {
  const failOn = options.failOn ?? 'error';

  const hasFail = files.some(f => f.status === 'FAIL');
  const hasWarn = files.some(f => f.status === 'WARN');
  const hasUnspecced = files.some(f => f.mode === 'Specless' || f.mode === 'Skipped');

  if (hasFail) return 'NO_SHIP';

  if (failOn === 'warning' && hasWarn) return 'NO_SHIP';
  if (failOn === 'unspecced' && hasUnspecced) return 'NO_SHIP';

  // TRUTH MODE: Block SHIP when no tests actually executed
  const hasTestData = files.some(f => f.testsTotal !== undefined && f.testsTotal > 0);
  const testsExecuted = files.reduce((sum, f) => sum + (f.testsExecuted ?? 0), 0);
  if (hasTestData && testsExecuted === 0) return 'NO_SHIP';

  // TRUTH MODE: Block SHIP when ALL specs are inferred with low confidence
  const specFiles = files.filter(f => f.specSource);
  const allLowConfidence = specFiles.length > 0 && specFiles.every(
    f => (f.specSource === 'inferred' || f.specSource === 'ai-assisted') && (f.specConfidence ?? 0) < 0.5
  );
  if (allLowConfidence && !options.guardrails?.allowAutoSpecShip) return 'WARN';

  // TRUTH MODE: Block SHIP when zero files were verified
  if (files.length === 0) return 'NO_SHIP';

  if (hasWarn) return 'WARN';
  return 'SHIP';
}

/**
 * Generate recommendations based on verification results.
 */
function generateUnifiedRecommendations(
  files: FileVerifyResultEntry[],
  coverage: { specced: number; total: number },
): string[] {
  const recs: string[] = [];

  // Recommend ISL spec generation for unspecced files
  const unspeccedFiles = files.filter(f => f.mode === 'Specless' || f.mode === 'Skipped');
  if (unspeccedFiles.length > 0) {
    // Group by directory (guard against undefined file paths)
    const dirs = new Set(unspeccedFiles.map(f => dirname(f.file ?? '.')).filter(Boolean));
    for (const dir of dirs) {
      recs.push(`Generate ISL specs: shipgate isl generate ${dir}/`);
    }
  }

  // Recommend fixing fake features
  const fakeFiles = files.filter(f => f.mode === 'Fake feature');
  if (fakeFiles.length > 0) {
    recs.push(`Fix fake/stub implementations in: ${fakeFiles.map(f => f.file ?? '').filter(Boolean).join(', ')}`);
  }

  // Recommend increasing coverage
  if (coverage.total > 0 && coverage.specced < coverage.total) {
    const pct = Math.round((coverage.specced / coverage.total) * 100);
    if (pct < 50) {
      recs.push(`ISL coverage is ${pct}% — aim for at least 80% spec coverage`);
    }
  }

  return recs;
}

/**
 * Compute the new summary fields from per-file results.
 * Returns trustScore, confidence, evidence, gaps, specSources, and why.
 */
function computeSummaryFields(
  files: FileVerifyResultEntry[],
  verdict: UnifiedVerdict,
): {
  trustScore: number;
  confidence: number;
  evidence: string;
  gaps: string[];
  specSources: { 'hand-written': number; inferred: number; 'ai-assisted': number };
  why: string[];
} {
  // ── Trust Score (0–100) ────────────────────────────────────────────────
  const avgScore = files.length > 0
    ? files.reduce((sum, f) => sum + f.score, 0) / files.length
    : 0;
  const trustScore = Math.round(avgScore * 100);

  // ── Evidence: aggregate test execution counts ──────────────────────────
  let totalExecuted = 0;
  let totalTests = 0;
  let hasTestData = false;
  for (const f of files) {
    if (f.testsExecuted !== undefined && f.testsTotal !== undefined) {
      totalExecuted += f.testsExecuted;
      totalTests += f.testsTotal;
      hasTestData = true;
    }
  }
  const evidence = hasTestData
    ? `tests executed: ${totalExecuted}/${totalTests}`
    : `executed: 0/${files.length} (no test data)`;

  // ── Spec Sources breakdown ─────────────────────────────────────────────
  const specSources: { 'hand-written': number; inferred: number; 'ai-assisted': number } = {
    'hand-written': 0,
    inferred: 0,
    'ai-assisted': 0,
  };
  for (const f of files) {
    if (f.specSource) {
      specSources[f.specSource]++;
    }
  }

  // ── Confidence (0.00–1.00) ─────────────────────────────────────────────
  // Weighted average: hand-written specs = 1.0, inferred use their specConfidence,
  // files with no spec = 0.0
  let confidenceSum = 0;
  let confidenceCount = 0;
  for (const f of files) {
    confidenceCount++;
    if (f.specSource === 'hand-written') {
      confidenceSum += 1.0;
    } else if (f.specSource === 'inferred' || f.specSource === 'ai-assisted') {
      confidenceSum += f.specConfidence ?? 0.3;
    } else {
      confidenceSum += 0.0;
    }
  }
  // Also factor in test execution ratio
  const testRatio = totalTests > 0 ? totalExecuted / totalTests : 0;
  const specConfidence = confidenceCount > 0 ? confidenceSum / confidenceCount : 0;
  const confidence = Math.round(Math.min(1, specConfidence * 0.6 + testRatio * 0.4) * 100) / 100;

  // ── Gaps: identify missing verification categories ─────────────────────
  const gaps: string[] = [];
  const failedFiles = files.filter(f => f.status === 'FAIL');
  const skippedFiles = files.filter(f => f.mode === 'Skipped');
  const inferredWithLowConf = files.filter(
    f => (f.specSource === 'inferred' || f.specSource === 'ai-assisted') && (f.specConfidence ?? 0) < 0.5
  );

  if (failedFiles.some(f => f.blockers.some(b => /postcondition/i.test(b)))) {
    gaps.push('missing postconditions');
  }
  if (failedFiles.some(f => f.blockers.some(b => /error|throw/i.test(b)))) {
    gaps.push('missing error cases');
  }
  if (files.some(f => f.blockers.some(b => /effect/i.test(b)))) {
    gaps.push('missing effects model');
  }
  if (hasTestData && totalExecuted === 0) {
    gaps.push('tests did not execute');
  }
  if (skippedFiles.length > 0) {
    gaps.push(`${skippedFiles.length} file(s) unspecced`);
  }
  if (inferredWithLowConf.length > 0) {
    gaps.push('low-confidence inferred specs');
  }
  // If no specific gaps found but verdict isn't SHIP, add generic gap
  if (gaps.length === 0 && verdict !== 'SHIP') {
    if (failedFiles.length > 0) gaps.push('verification failures');
  }

  // ── Why: top 3 reasons for the verdict ─────────────────────────────────
  const why: string[] = [];

  if (hasTestData && totalExecuted === 0 && totalTests > 0) {
    // Find first error that explains why tests didn't run
    const testError = files.flatMap(f => f.errors).find(e => /import|module|vitest|jest|spawn/i.test(e));
    why.push(testError
      ? `tests did not execute (${testError.slice(0, 60)})`
      : 'tests did not execute');
  } else if (hasTestData && totalExecuted < totalTests) {
    why.push(`only ${totalExecuted}/${totalTests} tests ran`);
  }

  for (const f of failedFiles) {
    if (why.length >= 3) break;
    const topBlocker = f.blockers[0];
    if (topBlocker) {
      why.push(topBlocker.length > 80 ? topBlocker.slice(0, 77) + '...' : topBlocker);
    }
  }

  for (const f of inferredWithLowConf) {
    if (why.length >= 3) break;
    why.push(`AI spec confidence ${(f.specConfidence ?? 0).toFixed(2)} (speculative rules unvalidated)`);
  }

  if (skippedFiles.length > 0 && why.length < 3) {
    why.push(`${skippedFiles.length} file(s) have no ISL spec`);
  }

  // Ensure at least one reason
  if (why.length === 0) {
    if (verdict === 'SHIP') {
      why.push('all checks passed');
    } else if (verdict === 'WARN') {
      why.push('warnings detected — review recommended');
    } else {
      why.push('verification did not pass');
    }
  }

  return {
    trustScore,
    confidence,
    evidence,
    gaps,
    specSources,
    why: why.slice(0, 3),
  };
}

/**
 * Build a proof bundle from per-file results for audit trail.
 * Surfaces all evidence, explicit gaps, confidence budget, and risk acceptances.
 */
function buildProofBundle(
  files: FileVerifyResultEntry[],
  verdict: UnifiedVerdict,
  options: UnifiedVerifyOptions,
): ProofBundle {
  const evidence: ProofEvidence[] = [];
  const gaps: ProofGap[] = [];
  const riskAcceptances: string[] = [];

  // Collect evidence and gaps from each file
  for (const f of files) {
    const file = f.file ?? '<unknown>';

    // Spec evidence
    if (f.specSource === 'hand-written') {
      evidence.push({
        source: 'isl-spec',
        check: `spec:${file}`,
        result: f.status === 'PASS' ? 'pass' : f.status === 'WARN' ? 'warn' : 'fail',
        confidence: 1.0,
        details: `Hand-written ISL spec: ${f.specFile}`,
      });
    } else if (f.specSource === 'inferred') {
      evidence.push({
        source: 'inference',
        check: `inferred-spec:${file}`,
        result: f.status === 'PASS' ? 'pass' : f.status === 'WARN' ? 'warn' : 'fail',
        confidence: f.specConfidence ?? 0.3,
        details: `Auto-inferred spec (confidence ${((f.specConfidence ?? 0) * 100).toFixed(0)}%)`,
      });
      if ((f.specConfidence ?? 0) < 0.5) {
        gaps.push({
          file,
          category: 'low-confidence',
          description: `Inferred spec confidence ${((f.specConfidence ?? 0) * 100).toFixed(0)}% — rules are speculative`,
          severity: 'high',
        });
      }
    } else if (f.specSource === 'ai-assisted') {
      evidence.push({
        source: 'ai-assisted',
        check: `ai-spec:${file}`,
        result: f.status === 'PASS' ? 'pass' : f.status === 'WARN' ? 'warn' : 'fail',
        confidence: f.specConfidence ?? 0.5,
        details: `AI-assisted spec (confidence ${((f.specConfidence ?? 0) * 100).toFixed(0)}%)`,
      });
    } else if (f.mode === 'Skipped') {
      evidence.push({
        source: 'static-analysis',
        check: `no-spec:${file}`,
        result: 'gap',
        confidence: 0,
        details: 'No ISL spec — no exported functions or types detected',
      });
      gaps.push({
        file,
        category: 'missing-spec',
        description: 'No ISL spec could be generated',
        severity: 'critical',
      });
    }

    // Test execution evidence
    if (f.testsTotal !== undefined && f.testsTotal > 0) {
      if (f.testsExecuted !== undefined && f.testsExecuted > 0) {
        evidence.push({
          source: 'test-execution',
          check: `tests:${file}`,
          result: f.status === 'FAIL' ? 'fail' : 'pass',
          confidence: f.testsExecuted / f.testsTotal,
          details: `${f.testsExecuted}/${f.testsTotal} tests executed`,
        });
      } else {
        evidence.push({
          source: 'test-execution',
          check: `tests-blocked:${file}`,
          result: 'fail',
          confidence: 0,
          details: 'Tests did not execute',
        });
        gaps.push({
          file,
          category: 'tests-not-executed',
          description: 'Generated tests failed to run (import errors, TS config, or runtime failure)',
          severity: 'critical',
        });
      }
    } else if (f.mode === 'ISL verified') {
      gaps.push({
        file,
        category: 'missing-tests',
        description: 'No test data available for this file',
        severity: 'high',
      });
    }

    // Blocker evidence
    for (const blocker of f.blockers) {
      if (/postcondition/i.test(blocker)) {
        gaps.push({ file, category: 'missing-postcondition', description: blocker, severity: 'high' });
      }
      if (/error|throw/i.test(blocker)) {
        gaps.push({ file, category: 'missing-error-case', description: blocker, severity: 'medium' });
      }
    }
  }

  // Risk acceptances from guardrails
  if (options.guardrails?.allowAutoSpecShip) {
    riskAcceptances.push('RISK_ACCEPTED: allowAutoSpecShip — auto-inferred specs can produce SHIP');
  }
  if (options.guardrails?.allowNoTestExecution) {
    riskAcceptances.push('RISK_ACCEPTED: allowNoTestExecution — SHIP without executed tests');
  }
  if (options.guardrails?.allowEmptyCategories) {
    riskAcceptances.push('RISK_ACCEPTED: allowEmptyCategories — missing verification categories allowed');
  }
  if (options.guardrails?.allowUnvalidatedAiRules) {
    riskAcceptances.push('RISK_ACCEPTED: allowUnvalidatedAiRules — AI rules without grounded evidence');
  }

  // Confidence budget
  const specFiles = files.filter(f => f.specSource);
  let specConfidenceSum = 0;
  for (const f of specFiles) {
    if (f.specSource === 'hand-written') specConfidenceSum += 1.0;
    else specConfidenceSum += f.specConfidence ?? 0.3;
  }
  const specConfidence = specFiles.length > 0 ? specConfidenceSum / specFiles.length : 0;

  let totalExecuted = 0;
  let totalTests = 0;
  for (const f of files) {
    totalExecuted += f.testsExecuted ?? 0;
    totalTests += f.testsTotal ?? 0;
  }
  const testExecutionRate = totalTests > 0 ? totalExecuted / totalTests : 0;

  const specced = files.filter(f => f.mode === 'ISL verified').length;
  const coverageRate = files.length > 0 ? specced / files.length : 0;

  const overallConfidence = Math.round(
    Math.min(1, specConfidence * 0.4 + testExecutionRate * 0.4 + coverageRate * 0.2) * 100
  ) / 100;

  const sufficient = verdict === 'SHIP' &&
    gaps.filter(g => g.severity === 'critical').length === 0 &&
    overallConfidence >= 0.7;

  return {
    evidence,
    gaps,
    confidenceBudget: {
      specConfidence: Math.round(specConfidence * 100) / 100,
      testExecutionRate: Math.round(testExecutionRate * 100) / 100,
      coverageRate: Math.round(coverageRate * 100) / 100,
      overallConfidence,
    },
    riskAcceptances,
    sufficient,
  };
}

/**
 * Unified verify entry point.
 * Auto-detects verification mode and runs the appropriate strategy.
 *
 * Usage:
 *   unifiedVerify('src/')                           — auto-detect
 *   unifiedVerify(undefined, { spec: 'a.isl', impl: 'a.ts' })  — explicit
 */
export async function unifiedVerify(
  targetPath: string | undefined,
  options: UnifiedVerifyOptions,
): Promise<UnifiedVerifyResult> {
  const startTime = Date.now();

  // ── Legacy single-spec mode ──────────────────────────────────────────────
  if (options.spec && options.impl) {
    const result = await verify(options.spec, {
      impl: options.impl,
      timeout: options.timeout ?? 30000,
      minScore: options.minScore ?? 70,
      verbose: options.verbose,
      report: options.report,
    });

    const relImpl = relative(process.cwd(), resolve(options.impl));
    const relSpec = relative(process.cwd(), resolve(options.spec));
    const score = result.trustScore
      ? Math.round((result.trustScore / 100) * 100) / 100
      : (result.success ? 0.85 : 0.3);

    const testsExecuted = result.verification?.testResult
      ? result.verification.testResult.passed + result.verification.testResult.failed
      : 0;
    const testsTotal = result.verification?.testResult
      ? result.verification.testResult.passed + result.verification.testResult.failed + result.verification.testResult.skipped
      : 0;

    const tier = classifyTier(resolve(options.impl), await readFile(resolve(options.spec), 'utf-8').catch(() => ''));
    const fileEntry: FileVerifyResultEntry = {
      file: relImpl,
      status: result.success ? 'PASS' : 'FAIL',
      mode: 'ISL verified',
      score,
      tier,
      specFile: relSpec,
      specSource: 'hand-written',
      testsExecuted,
      testsTotal,
      blockers: result.errors.map(e => `${relImpl}: ${e}`),
      errors: result.errors,
      duration: result.duration,
    };

    const verdict: UnifiedVerdict = result.success ? 'SHIP' : 'NO_SHIP';
    const summaryFields = computeSummaryFields([fileEntry], verdict);

    return {
      verdict,
      score,
      ...summaryFields,
      coverage: { specced: 1, total: 1 },
      files: [fileEntry],
      blockers: fileEntry.blockers,
      recommendations: [],
      mode: 'isl',
      duration: Date.now() - startTime,
      exitCode: result.success ? 0 : 1,
    };
  }

  // ── Auto-detect mode ──────────────────────────────────────────────────────
  const resolvedTarget = resolve(targetPath ?? '.');

  if (!existsSync(resolvedTarget)) {
    return {
      verdict: 'NO_SHIP',
      score: 0,
      trustScore: 0,
      confidence: 0,
      evidence: 'no files found',
      gaps: ['path does not exist'],
      specSources: { 'hand-written': 0, inferred: 0, 'ai-assisted': 0 },
      why: [`path does not exist: ${targetPath}`],
      coverage: { specced: 0, total: 0 },
      files: [],
      blockers: [`Path does not exist: ${targetPath}`],
      recommendations: [],
      mode: 'specless',
      duration: Date.now() - startTime,
      exitCode: 1,
    };
  }

  // Load ShipGate config (use defaults when no .shipgate.yml)
  const shipgateConfig = options.shipgateConfig ?? (await loadShipGateConfig(resolvedTarget)).config;

  const detection = await detectVerificationMode(resolvedTarget, shipgateConfig);
  const { mode, codeFiles, specMap } = detection;

  const projectRoot = resolvedTarget;

  // Normalize paths for config matching (Windows backslashes → forward slashes)
  const toRel = (abs: string) => relative(projectRoot, abs).replace(/\\/g, '/');

  // Use config-driven filter: only verify files that pass shouldVerify
  const relPaths = codeFiles.map(toRel);
  const filtered = filterVerifiableFiles(relPaths, shipgateConfig);
  const validFiles = filtered.map(({ path }) => resolve(projectRoot, path));

  if (options.verbose) {
    const ignorePatterns = getIgnorePatterns(shipgateConfig);
    console.error(chalk.gray(`[shipgate] Scan scope:`));
    console.error(chalk.gray(`  Target: ${resolvedTarget}`));
    console.error(chalk.gray(`  Ignore patterns: ${ignorePatterns.length} (from ci.ignore)`));
    console.error(chalk.gray(`  Code files found: ${codeFiles.length}`));
    console.error(chalk.gray(`  After shouldVerify filter: ${validFiles.length}`));
    console.error(chalk.gray(`  ISL specs found: ${detection.islFiles.length}`));
  }

  // Check requireIsl: files that MUST have hand-written ISL specs (before auto-generation)
  const specMapRel = new Map<string, string>();
  for (const [absCode, absSpec] of specMap) {
    specMapRel.set(toRel(absCode), toRel(absSpec));
  }
  const missingRequired = findMissingRequiredSpecs(
    filtered.map(({ path }) => path),
    specMapRel,
    shipgateConfig,
  );

  if (missingRequired.length > 0) {
    const blockers = missingRequired.map(
      (fp) => `${fp}: ISL spec required by ci.require_isl but missing`,
    );
    return {
      verdict: 'NO_SHIP',
      score: 0,
      trustScore: 0,
      confidence: 0,
      evidence: `${missingRequired.length} file(s) require ISL specs`,
      gaps: blockers,
      specSources: { 'hand-written': 0, inferred: 0, 'ai-assisted': 0 },
      why: blockers,
      coverage: { specced: 0, total: missingRequired.length },
      files: missingRequired.map((fp) => ({
        file: fp,
        status: 'FAIL' as const,
        mode: 'Skipped' as const,
        score: 0,
        blockers: [`${fp}: ISL spec required by ci.require_isl but missing`],
        errors: [] as string[],
        duration: 0,
      })),
      blockers,
      recommendations: [
        `Add .isl spec files for: ${missingRequired.slice(0, 5).join(', ')}${missingRequired.length > 5 ? ` (+${missingRequired.length - 5} more)` : ''}`,
      ],
      mode: detection.mode,
      duration: Date.now() - startTime,
      exitCode: 1,
    };
  }

  const fileResults: FileVerifyResultEntry[] = [];

  // ── Auto-generate ISL specs for unspecced files ────────────────────────
  const unspeccedFiles = validFiles.filter(f => !specMap.has(f));
  const generatedSpecsMap = new Map<string, GeneratedSpecInfo>();
  if (unspeccedFiles.length > 0) {
    const generatedSpecs = await autoGenerateSpecs(unspeccedFiles, projectRoot);
    for (const [codeFile, generatedSpec] of generatedSpecs) {
      specMap.set(codeFile, generatedSpec.specPath);
      generatedSpecsMap.set(codeFile, generatedSpec);
    }
  }

  // ── Verify all files against their specs (real or generated) ──────────
  for (const codeFile of validFiles) {
    const matchedSpec = specMap.get(codeFile);

    if (matchedSpec) {
      // Determine spec metadata (hand-written vs generated)
      const genInfo = generatedSpecsMap.get(codeFile);
      const specMeta: { source: SpecSource; confidence?: number } = genInfo
        ? { source: genInfo.source, confidence: genInfo.confidence }
        : { source: 'hand-written' };

      // ISL verification — traced per-file
      const result = await withSpan('verify.file', {
        attributes: {
          [ISL_ATTR.IMPL_FILE]: relative(process.cwd(), codeFile),
          [ISL_ATTR.SPEC_FILE]: relative(process.cwd(), matchedSpec),
          [ISL_ATTR.VERIFY_MODE]: 'isl',
        },
      }, async (fileSpan) => {
        const r = await runISLFileVerification(codeFile, matchedSpec, options, specMeta);
        fileSpan.setAttribute(ISL_ATTR.VERIFY_FILE_STATUS, r.status);
        fileSpan.setAttribute(ISL_ATTR.VERIFY_SCORE, r.score);
        fileSpan.setAttribute(ISL_ATTR.DURATION_MS, r.duration);
        if (r.status === 'FAIL') fileSpan.setError(r.blockers.join('; '));
        return r;
      });
      fileResults.push(result);
    } else {
      // No spec could be generated (e.g. no functions/types found) — mark as unverified
      // HONEST SCORING: unverified = 0, not 0.3. No evidence = no credit.
      const relPath = relative(process.cwd(), codeFile);
      const tier = classifyTier(codeFile);
      fileResults.push({
        file: relPath,
        status: 'FAIL',
        mode: 'Skipped',
        score: 0,
        tier,
        blockers: [`${relPath}: No ISL spec — no exported functions or types detected`],
        errors: [],
        duration: 0,
      });
    }
  }

  // If we found ISL files but no code files, report on the ISL files themselves
  if (codeFiles.length === 0 && detection.islFiles.length > 0) {
    for (const islFile of detection.islFiles) {
      const relPath = relative(process.cwd(), islFile);
      fileResults.push({
        file: relPath,
        status: 'WARN',
        mode: 'Skipped',
        score: 0,
        blockers: [`${relPath}: ISL spec found but no matching implementation`],
        errors: [],
        duration: 0,
      });
    }
  }

  // Calculate coverage
  const specced = fileResults.filter(f => f.mode === 'ISL verified').length;
  const total = fileResults.length;
  const coverage = { specced, total };

  // Build spec coverage report
  const specCoverage: SpecCoverageReport | undefined = options.specCoverage
    ? {
        withSpecs: fileResults
          .filter(f => f.specSource === 'hand-written' && f.specFile)
          .map(f => f.file),
        autoSpecced: fileResults
          .filter(f => f.specSource === 'inferred' && f.specFile)
          .map(f => f.file),
        unspecced: fileResults
          .filter(f => f.mode === 'Skipped' || !f.specFile)
          .map(f => f.file),
      }
    : undefined;

  // Calculate overall score (tiered weighting: Tier 1=3x, Tier 2=2x, Tier 3=1x)
  let avgScore: number;
  if (options.useTieredScoring !== false && fileResults.some(f => f.tier != null)) {
    const fileScores = fileResults
      .filter(f => f.tier != null)
      .map(f => ({ file: f.file, score: f.score, tier: f.tier! }));
    const { overallScore } = calculateWeightedTrustScore(fileScores);
    avgScore = overallScore;
  } else {
    avgScore = total > 0
      ? Math.round((fileResults.reduce((sum, f) => sum + f.score, 0) / total) * 100) / 100
      : 0;
  }

  // Determine verdict
  const verdict = calculateVerdict(fileResults, options);

  // Collect blockers
  const blockers = fileResults.flatMap(f => f.blockers);

  // Generate recommendations
  const recommendations = generateUnifiedRecommendations(fileResults, coverage);

  // Calculate exit code
  let exitCode: number;
  switch (verdict) {
    case 'SHIP': exitCode = 0; break;
    case 'NO_SHIP': exitCode = 1; break;
    case 'WARN': exitCode = 4; break;
  }

  const summaryFields = computeSummaryFields(fileResults, verdict);

  // Build proof bundle for audit trail
  const proofBundle = buildProofBundle(fileResults, verdict, options);

  const unifiedResult: UnifiedVerifyResult = {
    verdict,
    score: avgScore,
    ...summaryFields,
    coverage,
    specCoverage,
    files: fileResults,
    blockers,
    recommendations,
    mode,
    duration: Date.now() - startTime,
    exitCode,
    proofBundle,
  };

  // Generate explain reports if requested
  if (options.explain) {
    try {
      const { generateExplainReportsForVerify } = await import('./verify-explain.js');
      const outputDir = options.report && !options.report.includes('.') 
        ? options.report 
        : './reports';
      const reports = await generateExplainReportsForVerify(unifiedResult, outputDir);
      if (options.verbose) {
        console.error(chalk.gray(`[shipgate] Explain reports generated:`));
        console.error(chalk.gray(`  - ${reports.jsonPath}`));
        console.error(chalk.gray(`  - ${reports.mdPath}`));
      }
    } catch (err) {
      if (options.verbose) {
        console.error(chalk.yellow(`[shipgate] Failed to generate explain reports: ${err instanceof Error ? err.message : String(err)}`));
      }
    }
  }

  return unifiedResult;
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — Exit Code
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Get process exit code for a unified verify result.
 */
export function getUnifiedExitCode(result: UnifiedVerifyResult): number {
  return result.exitCode;
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — Terminal Output
// ─────────────────────────────────────────────────────────────────────────────

const VERSION_TAG = 'v0.1.0';

/**
 * Print the structured terminal output for unified verification.
 *
 * The output is designed to be impossible to misread:
 * - Verdict, Trust Score, Confidence, Evidence, Gaps, Spec Source, Why
 * - One-line verdict summary at the bottom
 */
export function printUnifiedVerifyResult(
  result: UnifiedVerifyResult,
  options: {
    json?: boolean;
    ci?: boolean;
    format?: OutputFormat;
    verbose?: boolean;
    detailed?: boolean;
  } = {},
): void {
  // ── Format-specific output ─────────────────────────────────────────────
  const format = options.format || (options.json ? 'json' : undefined) || (options.ci ? 'github' : undefined);
  
  if (format === 'gitlab') {
    console.log(formatGitLab(result));
    return;
  }
  
  if (format === 'junit') {
    console.log(formatJUnit(result));
    return;
  }
  
  // ── JSON output ──────────────────────────────────────────────────────────
  if (format === 'json' || options.json) {
    printUnifiedJSON(result);
    return;
  }

  // ── CI output (GitHub Actions annotations) ───────────────────────────────
  if (format === 'github' || options.ci) {
    printUnifiedCI(result);
    return;
  }

  // ── Pretty terminal output ───────────────────────────────────────────────
  const separator = chalk.gray('\u2500'.repeat(72));
  const thinSep = chalk.gray('\u2500'.repeat(72));

  console.log('');
  console.log(chalk.bold.cyan(`ShipGate ISL Verify ${VERSION_TAG}`));
  console.log(separator);

  // File table
  if (result.files.length === 0) {
    console.log(chalk.gray('  No files found to verify.'));
  } else {
    for (const file of result.files) {
      const statusIcon = file.status === 'PASS'
        ? chalk.green('\u2713')
        : file.status === 'WARN'
          ? chalk.yellow('\u26A0')
          : chalk.red('\u2717');

      const statusLabel = file.status === 'PASS'
        ? chalk.green('PASS')
        : file.status === 'WARN'
          ? chalk.yellow('WARN')
          : chalk.red('FAIL');

      const modeLabel = file.mode === 'ISL verified'
        ? chalk.cyan('ISL verified')
        : file.mode === 'Specless'
          ? chalk.yellow('Specless')
          : file.mode === 'Fake feature'
            ? chalk.red('Fake feature')
            : chalk.gray('Skipped');

      const scoreStr = file.score > 0
        ? (file.score >= 0.8 ? chalk.green : file.score >= 0.5 ? chalk.yellow : chalk.red)(
            file.score.toFixed(2),
          )
        : chalk.gray('-.--');

      const filePad = file.file.length > 35 ? file.file.slice(-35) : file.file.padEnd(35);
      console.log(
        `  ${filePad} ${statusIcon} ${statusLabel.padEnd(14)} ${modeLabel.padEnd(22)} ${scoreStr}`,
      );
    }
  }

  console.log(separator);

  // ── Core summary fields (impossible to misread) ──────────────────────────
  const verdictColor =
    result.verdict === 'SHIP'
      ? chalk.green
      : result.verdict === 'WARN'
        ? chalk.yellow
        : chalk.red;

  console.log(chalk.bold('Verdict:      ') + verdictColor.bold(result.verdict));
  console.log(chalk.bold('Trust Score:  ') + formatTrustScoreColor(result.trustScore) + chalk.gray('/100'));
  console.log(chalk.bold('Confidence:   ') + formatConfidenceColor(result.confidence));
  console.log(chalk.bold('Evidence:     ') + result.evidence);

  // Gaps
  if (result.gaps.length > 0) {
    console.log(chalk.bold('Gaps:         ') + chalk.yellow(result.gaps.join('; ')));
  } else {
    console.log(chalk.bold('Gaps:         ') + chalk.green('none'));
  }

  // Spec Source breakdown
  const srcParts: string[] = [];
  if (result.specSources['hand-written'] > 0) srcParts.push(`${result.specSources['hand-written']} hand-written`);
  if (result.specSources.inferred > 0) srcParts.push(`${result.specSources.inferred} inferred`);
  if (result.specSources['ai-assisted'] > 0) srcParts.push(`${result.specSources['ai-assisted']} AI-assisted`);
  const unspeccedCount = result.files.filter(f => !f.specSource).length;
  if (unspeccedCount > 0) srcParts.push(`${unspeccedCount} unspecced`);
  console.log(chalk.bold('Spec Source:  ') + (srcParts.length > 0 ? srcParts.join(', ') : chalk.gray('none')));

  // Spec coverage report (when --spec-coverage)
  if (result.specCoverage) {
    console.log('');
    console.log(chalk.bold('Spec Coverage:'));
    console.log(chalk.gray('  With specs:    ') + result.specCoverage.withSpecs.length);
    if (result.specCoverage.withSpecs.length > 0 && options.verbose) {
      for (const f of result.specCoverage.withSpecs.slice(0, 10)) {
        console.log(chalk.gray('    - ') + f);
      }
      if (result.specCoverage.withSpecs.length > 10) {
        console.log(chalk.gray(`    ... and ${result.specCoverage.withSpecs.length - 10} more`));
      }
    }
    console.log(chalk.gray('  Auto-specced: ') + result.specCoverage.autoSpecced.length);
    if (result.specCoverage.autoSpecced.length > 0 && options.verbose) {
      for (const f of result.specCoverage.autoSpecced.slice(0, 10)) {
        console.log(chalk.gray('    - ') + f);
      }
      if (result.specCoverage.autoSpecced.length > 10) {
        console.log(chalk.gray(`    ... and ${result.specCoverage.autoSpecced.length - 10} more`));
      }
    }
    console.log(chalk.gray('  Unspecced:    ') + result.specCoverage.unspecced.length);
    if (result.specCoverage.unspecced.length > 0 && options.verbose) {
      for (const f of result.specCoverage.unspecced.slice(0, 10)) {
        console.log(chalk.gray('    - ') + f);
      }
      if (result.specCoverage.unspecced.length > 10) {
        console.log(chalk.gray(`    ... and ${result.specCoverage.unspecced.length - 10} more`));
      }
    }
  }

  // Why (top 3 reasons)
  if (result.why.length > 0) {
    console.log(chalk.bold('Why:'));
    for (let i = 0; i < result.why.length; i++) {
      console.log(`  ${i + 1}. ${result.why[i]}`);
    }
  }

  console.log(thinSep);

  // ── One-line verdict (the line that prevents fake safety) ─────────────
  const oneLiner = buildOneLineSummary(result);
  console.log('');
  console.log(verdictColor.bold(oneLiner));
  console.log('');

  // Recommendations (verbose/detailed only)
  if ((options.verbose || options.detailed) && result.recommendations.length > 0) {
    console.log(chalk.bold.cyan('Recommendations:'));
    for (const rec of result.recommendations) {
      console.log(chalk.cyan(`  \u2022 ${rec}`));
    }
    console.log('');
  }

  console.log(chalk.gray(`Duration: ${result.duration}ms | Mode: ${result.mode} | Coverage: ${result.coverage.specced}/${result.coverage.total}`));
  console.log('');
}

/**
 * Build the single-line verdict summary that is impossible to misread.
 * Example: NO_SHIP: tests did not execute (vitest import error); postconditions missing; AI spec confidence 0.42 (speculative rules unvalidated).
 */
function buildOneLineSummary(result: UnifiedVerifyResult): string {
  const parts: string[] = [];

  // Add why reasons
  for (const reason of result.why) {
    parts.push(reason);
  }

  // If no specific reasons, fall back to gaps
  if (parts.length === 0) {
    for (const gap of result.gaps) {
      parts.push(gap);
    }
  }

  // If still empty, use evidence
  if (parts.length === 0) {
    parts.push(result.evidence);
  }

  return `${result.verdict}: ${parts.join('; ')}.`;
}

function formatTrustScoreColor(score: number): string {
  if (score >= 85) return chalk.green(String(score));
  if (score >= 70) return chalk.cyan(String(score));
  if (score >= 50) return chalk.yellow(String(score));
  return chalk.red(String(score));
}

function formatConfidenceColor(confidence: number): string {
  const str = confidence.toFixed(2);
  if (confidence >= 0.8) return chalk.green(str);
  if (confidence >= 0.5) return chalk.yellow(str);
  return chalk.red(str);
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — JSON Output
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Print machine-readable JSON output for CI pipelines.
 */
function printUnifiedJSON(result: UnifiedVerifyResult): void {
  const payload = {
    verdict: result.verdict,
    trustScore: result.trustScore,
    confidence: result.confidence,
    evidence: result.evidence,
    gaps: result.gaps,
    specSources: result.specSources,
    why: result.why,
    score: result.score,
    coverage: result.coverage,
    mode: result.mode,
    files: result.files.map(f => ({
      file: f.file,
      status: f.status,
      mode: f.mode,
      score: f.score,
      specFile: f.specFile ?? null,
      specSource: f.specSource ?? null,
      specConfidence: f.specConfidence ?? null,
      testsExecuted: f.testsExecuted ?? null,
      testsTotal: f.testsTotal ?? null,
      blockers: f.blockers,
      errors: f.errors,
      duration: f.duration,
    })),
    blockers: result.blockers,
    recommendations: result.recommendations,
    duration: result.duration,
    exitCode: result.exitCode,
    summary: buildOneLineSummary(result),
  };
  // Secrets are automatically masked
  console.log(safeJSONStringify(payload, undefined, 2));
}

// ─────────────────────────────────────────────────────────────────────────────
// Unified Verify — CI Output (GitHub Actions Annotations)
// ─────────────────────────────────────────────────────────────────────────────

/**
 * Print CI-friendly output:
 * - JSON to stdout
 * - GitHub Actions annotations to stderr
 * - One-line summary to stderr
 */
function printUnifiedCI(result: UnifiedVerifyResult): void {
  // JSON payload to stdout (for artifact capture)
  printUnifiedJSON(result);

  // GitHub Actions annotations to stderr
  for (const file of result.files) {
    if (file.status === 'FAIL') {
      const msg = file.blockers.length > 0 ? file.blockers[0] : `Verification failed (score: ${file.score})`;
      process.stderr.write(`::error file=${file.file}::${msg}\n`);
    } else if (file.status === 'WARN') {
      const msg = file.mode === 'Specless'
        ? `No ISL spec found (specless verification, score: ${file.score})`
        : `Warning (score: ${file.score})`;
      process.stderr.write(`::warning file=${file.file}::${msg}\n`);
    } else {
      process.stderr.write(`::notice file=${file.file}::PASS (${file.mode}, score: ${file.score})\n`);
    }
  }

  // One-line verdict summary to stderr (impossible to misread)
  const summary = buildOneLineSummary(result);
  process.stderr.write(`\n${summary}\n`);
}

export default verify;
